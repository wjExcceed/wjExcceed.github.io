[{"title":"a","date":"2019-07-15T02:56:57.000Z","path":"2019/07/15/a/","text":"","categories":[],"tags":[]},{"title":"Java内存模型——JMM","date":"2017-08-28T13:19:15.000Z","path":"2017/08/28/Java内存模型——JMM/","text":"JMM 全称,Java Memory Model. 这个内存模型与Stack，heap GC分代的内存模型，不是一回事，两者是通过不通的维度，将硬件访问抽象出来的一层抽象的逻辑模型，JVM屏蔽了硬件的直接操作。 GC分代的内存模型更加贴近与垃圾回收和内存分配使用的理解，而JMM模型更加贴近，多线程和内存之间的通讯。 工作内存和主内存Java内存模型规定了所有的变量都存储在主内存（Main Memory）中。每条线程还有自己的工作内存，线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 需要注意的是， 放在主内存的变量包括，实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程独有的。 内存间的交互操作线程间如果要完成变成的同步和共享，必须经历下面2个步骤。 线程A必须要把线程A的工作内存更新过的变量刷新到主内存去。 线程B到主内存中去读取线程A更新过的共享变量 这些通讯操作是被JMM屏蔽的，要保证变量的线程安全共享需要使用Java的同步块(synchonrized），或者其他并发工具。这里强调的是安全共享，在不加同步块，和并发工具的情况下，变量也是可以被共享的，只是不能保证读都最新数据，就是常说的脏读，错读等。","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"record","slug":"record","permalink":"/tags/record/"},{"name":"java","slug":"java","permalink":"/tags/java/"}]},{"title":"聊聊操作系统","date":"2017-08-20T15:22:45.000Z","path":"2017/08/20/聊聊操作系统/","text":"LinuxSWAP的概述SWAP就是LINUX下的虚拟内存分区，它的作用是在物理内存使用完之后,将磁盘空间(也就是SWAP分区)虚拟成内存来使用。 SWAP的作用可简单描述为：当内存不够用时，将存储器中的数据块从DRAM移到SWAP的磁盘空间中，以释放更多的空间给当前进程使用。当再次需要那些数据时，就可以将swap磁盘中的数据重新移到内存，而将那些不用的数据块从内存移到SWAP中。 数据从内存移动交换区的行为被称为页面调用，发生在后台的页面调用没有来自应用程序的干涉。 SWAP空间是分页的，每一页的大小和内存也大小是一样的。 并不是一定要给每个系统划分SWAP，比如大多数的嵌入式就没有SWAP分区。 值得注意的是：并不是所有从物理内存中交换出来的数据都会被放到Swap中（如果这样的话，Swap就会不堪重负），有相当一部分数据被直接交换到文件系统。例如，有的程序会打开一些文件，对文件进行读写（其实每个程序都至少要打开一个文件，那就是运行程序本身），当需要将这些程序的内存空间交换出去时，就没有必要将文件部分的数据放到Swap空间中了，而可以直接将其放到文件里去。如果是读文件操作，那么内存数据被直接释放，不需要交换出来，因为下次需要时，可直接从文件系统恢复；如果是写文件，只需要将变化的数据保存到文件中，以便恢复。但是那些用malloc和new函数生成的对象的数据则不同，它们需要Swap空间，因为它们在文件系统中没有相应的“储备”文件，因此被称作“匿名”(Anonymous)内存数据。这类数据还包括堆栈中的一些状态和变量数据等。所以说，Swap空间是“匿名”数据的交换空间。 fork函数fork（）函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。 一个进程调用fork（）函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。 当执行fork()函数后，会生成一个子进程，子进程的执行从fork()的返回值开始且代码继续往下执行。 fork()执行一次后会有两次返回值：第一次为原来的进程，即父进程会有一次返回值，表示新生成的子进程的进程ID；第二次为子进程的起始执行，返回值为0。 fork函数的返回值fpid=fork()值为什么在父子进程中不同。“其实就相当于链表，进程形成了链表，父进程的fpid(p 意味point)指向子进程的进程id, 因为子进程没有子进程，所以其fpid为0。 fork()可能有三种不同的返回值：1）在父进程中，fork返回新创建子进程的进程ID；2）在子进程中，fork返回0；3）如果出现错误，fork返回一个负值； fork出错的原因1）当前的进程数已经达到了系统规定的上限，这时errno的值被设置为EAGAIN。2）系统内存不足，这时errno的值被设置为ENOMEM。 fork使用场景 守护进程&emsp;&emsp;有时为了保护主进程不被杀，或者主进程异外退出后仍可再次启动(或后台运行)，就执行fork()让子进程监控主进程的运行状态，根据监听保护主进程的运行。 框架扩展&emsp;&emsp;主进程只负责生成子进程，派出子进程去执行应用框架下的子任务，这些任务可能多变、可能更新频繁，但配合fork()及exec()函数，一切都是so easy..还保证了主进程的稳定，避免频繁更新程序。 管程定义管程的定义：由表示共享资源的抽象数据结构和对该共享数据结构的一组操作所组成的资源管理程序叫管程 。管程封装了共享资源及对于共享资源的操作，别的进程不能直接访问这些资源，因此管程也可以成为资源管理类。 一个管程定义了一个数据结构和对该数据结构上的一组操作，这组操作能同步进程并改变管程中的数据。 局部于管程的数据结构，只能被局部于管程的操作所访问，任何管程之外的操作都不能访问它；反之，局部于管程的操作也只能访问管程内的数据结构。由此可见，管程相当于围墙，它把共享变量和对它进行操作的若干个过程围了起来，所有进程要访问临界资源时，都必须经过管程才能进入，而管程每次只允许一个进程进入管程，从而实现了进程的互斥。 管程的组成 一个互斥锁：进入管程时加锁，离开管程时解锁 —— 用于确保了在一个时间点，最多只有一个线程占用该管程。 共享资源的数据结构：用于表示管程内部的共享资源 对共享资源（数据结构）的一组操作：用于同步进程并改变管程中的数据 一个用来避免竞态条件的不变量：用于判断管程内部的共享资源是否能被使用（在进入管程后，离开管程前判断） 紧急等待队列：用于存放等待管程或共享资源的使用权的进程 管程的优势 集中化管理资源：管程实现了同一时刻最多只有一个线程执行管程的某个子程序。与那些通过修改数据结构实现互斥访问的并发程序设计相比，管程很大程度上简化了程序设计 —— 类似于将原来的分布式资源管理变成集中式资源管理。 互斥地使用管程：管程把共享变量和对它进行操作的若干个过程围了起来，所有进程要访问临界资源时，都必须经过管程才能进入，而管程每次只允许一个进程进入管程，从而实现了进程的互斥。 管程内部信息隐藏：管程外的进程或其他软件模块只能通过管程对外的接口来访问管程提供的操作，管程内部的实现细节对外界是透明的。 使系统中的各种硬件资源和软件资源，均可用数据结构抽象地描述其资源特性，即用少量信息和对资源所执行的操作来表示该资源，从而忽略它们的内部结构和实现细节。 死锁四个必要条件〈1〉互斥条件。即某个资源在一段时间内只能由一个进程占有，不能同时被两个或两个以上的进程占有。这种独占资源如CD-ROM驱动器，打印机等等，必须在占有该资源的进程主动释放它之后，其它进程才能占有该资源。这是由资源本身的属性所决定的。如独木桥就是一种独占资源，两方的人不能同时过桥。 〈2〉不可抢占条件。进程所获得的资源在未使用完毕之前，资源申请者不能强行地从资源占有者手中夺取资源，而只能由该资源的占有者进程自行释放。如过独木桥的人不能强迫对方后退，也不能非法地将对方推下桥，必须是桥上的人自己过桥后空出桥面（即主动释放占有资源），对方的人才能过桥。 〈3〉占有且申请条件。进程至少已经占有一个资源，但又申请新的资源；由于该资源已被另外进程占有，此时该进程阻塞；但是，它在等待新资源之时，仍继续占用已占有的资源。还以过独木桥为例，甲乙两人在桥上相遇。甲走过一段桥面（即占有了一些资源），还需要走其余的桥面（申请新的资源），但那部分桥面被乙占有（乙走过一段桥面）。甲过不去，前进不能，又不后退；乙也处于同样的状况。 〈4〉循环等待条件。存在一个进程等待序列{P1，P2，…，Pn}，其中P1等待P2所占有的某一资源，P2等待P3所占有的某一源，……，而Pn等待P1所占有的的某一资源，形成一个进程循环等待环。就像前面的过独木桥问题，甲等待乙占有的桥面，而乙又等待甲占有的桥面，从而彼此循环等待。 解决死锁的策略(1) 死锁预防：破坏导致死锁必要条件中的任意一个就可以预防死锁。例如，要求用户申请资源时一次性申请所需要的全部资源，这就破坏了保持和等待条件；将资源分层，得到上一层资源后，才能够申请下一层资源，它破坏了环路等待条件。预防通常会降低系统的效率。 (2) 死锁避免：避免是指进程在每次申请资源时判断这些操作是否安全，例如，使用银行家算法。死锁避免算法的执行会增加系统的开销。 (3) 死锁检测：死锁预防和避免都是事前措施，而死锁的检测则是判断系统是否处于死锁状态，如果是，则执行死锁解除策略。 (4) 死锁解除：这是与死锁检测结合使用的，它使用的方式就是剥夺。即将某进程所拥有的资源强行收回，分配给其他的进程。 鸵鸟算法该算法可以应用在极少发生死锁的的情况下。为什么叫鸵鸟算法呢，因为传说中鸵鸟看到危险就把头埋在地底下，可能鸵鸟觉得看不到危险也就没危险了吧。跟掩耳盗铃有点像。 银行家算法所谓银行家算法，是指在分配资源之前先看清楚，资源分配后是否会导致系统死锁。如果会死锁，则不分配，否则就分配。 按照银行家算法的思想，当进程请求资源时，系统将按如下原则分配系统资源： (1) 当一个进程对资源的最大需求量不超过系统中的资源数时可以接纳该进程。 (2) 进程可以分期请求资源，当请求的总数不能超过最大需求量。 (3) 当系统现有的资源不能满足进程尚需资源数时，对进程的请求可以推迟分配，但总能使进程在有限的时间里得到资源。 (4) 当系统现有的资源能满足进程尚需资源数时，必须测试系统现存的资源能否满足该进程尚需的最大资源数，若能满足则按当前的申请量分配资源，否则也要推迟分配。 mmap概念&emsp;&emsp;内存映射，简而言之就是将内核空间的一段内存区域映射到用户空间。映射成功后，用户对这段内存区域的修改可以直接反映到内核空间，相反，内核空间对这段区域的修改也直接反映用户空间。那么对于内核空间与用户空间两者之间需要大量数据传输等操作的话效率是非常高的。当然，也可以将内核空间的一段内存区域同时映射到多个进程，这样还可以实现进程间的共享内存通信。 &emsp;&emsp;系统调用mmap()就是用来实现上面说的内存映射。最常见的操作就是文件（在Linux下设备也被看做文件）的操作，可以将某文件映射至内存(进程空间)，如此可以把对文件的操作转为对内存的操作，以此避免更多的lseek()与read()、write()操作，这点对于大文件或者频繁访问的文件而言尤其受益。 &emsp;&emsp;采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据：一次从输入文件到共享内存区，另一次从共享内存区到输出文件。实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。 使用场景1、提高I/O效率2、匿名内存映射3、共享内存进程通信 mmap()函数&emsp;&emsp;用户空间mmap()函数的形式如下1void *mmap(void *start, size_t length, int prot, int flags,int fd, off_t offset) 下面就其参数解释如下： start：用户进程中要映射的用户空间的起始地址，通常为NULL（由内核来指定） length：要映射的内存区域的大小 prot：期望的内存保护标志 flags：指定映射对象的类型 fd：文件描述符（由open函数返回） offset：设置在内核空间中已经分配好的的内存区域中的偏移，例如文件的偏移量，大小为PAGE_SIZE的整数倍 返回值：mmap()返回被映射区的指针，该指针就是需要映射的内核空间在用户空间的虚拟地址 匿名内存映射&emsp;&emsp;匿名映射是指参数fd=-1的映射，此时不通过文件共享内存，适用于父子进程之间。在父进程中先调用mmap()，然后调用 fork()。那么在调用fork()之后，子进程继承父进程匿名映射后的地址空间，同样也继承mmap()返回的地址，这样，父子进程就可以通过映射区 域进行通信了。注意，这里不是一般的继承关系。一般来说，子进程单独维护从父进程继承下来的一些变量。而mmap()返回的地址，却由父子进程共同维护。 对于具有亲缘关系的进程实现共享内存最好的方式应该是采用匿名内存映射的方式。 使用mmap的细节1、使用mmap需要注意的一个关键点是，mmap映射区域大小必须是物理页大小(page_size)的整倍数（32位系统中通常是4k字节）。原因是，内存的最小粒度是页，而进程虚拟地址空间和内存的映射也是以页为单位。为了匹配内存的操作，mmap从磁盘到虚拟地址空间的映射也必须是页。 2、内核可以跟踪被内存映射的底层对象（文件）的大小，进程可以合法的访问在当前文件大小以内又在内存映射区以内的那些字节。也就是说，如果文件的大小一直在扩张，只要在映射区域范围内的数据，进程都可以合法得到，这和映射建立时文件的大小无关。具体情形参见“情形三”。 3、映射建立之后，即使文件关闭，映射依然存在。因为映射的是磁盘的地址，不是文件本身，和文件句柄无关。同时可用于进程间通信的有效地址空间不完全受限于被映射文件的大小，因为是按页映射。 使用mmap的优点1、对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率。 2、实现了用户空间和内核空间的高效交互方式。两空间的各自修改操作可以直接反映在映射的区域内，从而被对方空间及时捕捉。 3、提供进程间共享内存及相互通信的方式。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的。 同时，如果进程A和进程B都映射了区域C，当A第一次读取C时通过缺页从磁盘复制文件页到内存中；但当B再读C的相同页面时，虽然也会产生缺页异常，但是不再需要从磁盘中复制文件过来，而可直接使用已经保存在内存中的文件数据。 4、可用于实现高效的大规模数据传输。内存空间不足，是制约大数据操作的一个方面，解决方案往往是借助硬盘空间协助操作，补充内存的不足。但是进一步会造成大量的文件I/O操作，极大影响效率。这个问题可以通过mmap映射很好的解决。换句话说，但凡是需要用磁盘空间代替内存的时候，mmap都可以发挥其功效。 相关的系统调用1int munmap( void * addr, size_t len ) 该调用在进程地址空间中解除一个映射关系，addr是调用mmap()时返回的地址，len是映射区的大小。当映射关系解除，对原来映射地址的访问将导致段错误发生。 1int msync ( void * addr , size_t len, int flags) 一般说来，进程在映射空间的对共享内容的改变并不直接写回到磁盘文件中，往往在调用munmap（）后才执行该操作。可以通过调用msync()实现磁盘上文件内容与共享内存区的内容一致。","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"Operating System","slug":"Operating-System","permalink":"/tags/Operating-System/"}]},{"title":"I/O多路复用","date":"2017-08-20T13:04:13.000Z","path":"2017/08/20/I-O多路复用/","text":"&emsp;&emsp;select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。关于这三种IO多路复用的用法，前面三篇总结写的很清楚，并用服务器回射echo程序进行了测试。 阻塞 I/O（blocking IO） 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 非阻塞 I/O（nonblocking IO） 当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。 I/O 多路复用（IO multiplexing） IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 异步 I/O（asynchronous IO） 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 小结： 通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。 blocking和non-blocking的区别调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。 synchronous IO和asynchronous IO的区别两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 有人会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。 I/O多路复用详解select1int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。 select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。 poll1int poll (struct pollfd *fds, unsigned int nfds, int timeout); pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 epoll123int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) epoll与select/poll的比较select的几大缺点： 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 select支持的文件描述符数量太小了，默认是1024 ============= epoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。 对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。 对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。 对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。 ============= epoll与select/poll的小结1、监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右2、IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。3、epoll支持LT、ET两种工作模式，而select/poll只支持LT。 工作模式 LT模式（水平触发） LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。 通俗地讲，当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它还会通知你在上没读写完的文件描述符上继续读写，当然如果你一直不去读写，它会一直通知你！！！如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率！！！ ET模式（边沿触发） ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once) 通俗地讲，当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你！！！这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符！！！ ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"Operating System","slug":"Operating-System","permalink":"/tags/Operating-System/"}]},{"title":"TCP/UDP的归纳总结","date":"2017-08-20T10:39:36.000Z","path":"2017/08/20/TCP-UDP的归纳总结/","text":"&emsp;&emsp;运输层是整个网络体系结构中的关键层次之一，它有一个很重要的功能就是复用和分用。这里的“复用”是指在发送方不同的应用进程都可以使用同一个运输层协议传输数据，而“分用”是指接收方的运输层在剥去报文的首部后就能够把这些数据正确交付到目的应用进程。 从这里可以看出网络层和运输层有明显的区别。网络层是为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信。 用户数据协议UDP的特点 UDP是无连接的，即发送数据之前不需要建立连接（当然发送数据结束时也没有连接可以释放），因此减少了开销和发送数据之前的时延。 UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的连接状态表。 UDP是面向报文的。发送方的UDP对应用程序交下来的报文，在添加手部后就向下交付给IP层。UDP对应用层家下来的报文，既不合并，也不拆分，而是保留这些文件的边界。 UDP没有拥塞控制，因此网络出现的拥塞不会使源主机的发送速率降低。这对实时应用是很重要的。很多实时应用（如IP电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太大的时延。 UDP支持一对一、一对多、多对一和多对多的交互通信。 UDP的首部开销校，只有8个字节，比TCP的20个字节的首部要短。 UDP的首部格式 &emsp;&emsp;用户数据包UDP有两个字段：数据字段和首部字段。首部字段很简单，只有8个字节，由四个字段组成，每个字段的长度都是两个字节。各字段意义如下：(1)源端口： 源端口号，在需要对方回信时选用，不需要时可用全0。(2)目的端口： 目的端口号。这在重点交付报文时必须要使用到。(3)长度： UDP用户数据包的长度，其最小值是8（仅有首部）(4)检验和： 检测UDP用户数据包在传输中是否有错。有错就丢弃。注意：IP数据包的检验和只检验IP数据包的首部，但UDP的检验和是把首部和数据部分一起都检验。 传输控制协议TCP的特点 TCP是面向连接的运输层协议。这就是说，应用程序在使用TCP协议之前，必须先建立TCP连接。在传输数据完毕后，必须释放已经建立的TCP连接。 每一条TCP连接只能有两个端点。每一条TCP连接只能是点对点的（一对一）。 TCP提供可靠交付的服务。也就是说，通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达。 TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给TCP缓存后，就可以做自己的事，而TCP在合适的时候把数据发送出去。在接收时，TCP把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。 面向字节流。TCP中的“流”指的是流入到进程或从进程流出的字节序列。“面向字节流”的含义是虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序交下来的数据看成仅仅是一连串的无结构字节流。TCP并不知道所传送的字节流的含义。TCP不保证接收方应用程序所收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系。 TCP报文段的首部格式TCP虽然是面向字节流的，但TCP传送的数据单元却是报文段。一个TCP报文段分为首部和数据两部分。TCP报文段首部的前20个字节是固定的，后面有4N字节是根据需要而增加的选项。所以TCP首部的最小长度是20字节。 (1)源端口和目的端口： 各占两个字节，与UDP的分用相似，TCP的分用功能也是通过端口实现。 (2)序号： 占4字节。TCP是面向字节流的。在一个TCP连接中传送的字节流中的每一个字节都按顺序编号。整个要传送的字节流的起始序号必须在连接建立时设置。首部中的序号字段值指的是本报文段所发送的数据的第一个字节的序号。 (3)确认号： 占4字节。是期望收到对方下一个报文段的第一个数据字节的序号。若确认号=N，则表明：到序号N-1为止的所有数据都已正确收到。 (4)数据偏移： 占4bit。他指出TCP报文段的数据起始处距离TCP报文段的起始处有多远。这个字段实际上指出TCP报文段的首部长度。 (5)保留： 占6bit。保留为今后使用，目前应置为0。 (6)紧急URG： 1bit。当URG=1时，表明紧急指针字段有效。他告诉系统此报文段中有紧急数据，应尽快传送，而不按原来的排队顺序来传送。于是发送方TCP就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍是普通数据，这时要与首部中紧急指针字段配合使用。 (7)确认ACK： 1bit。仅当ACK=1时确认号字段才有效。当ACK=0时，确认号无效。TCP规定，在连接建立后所有传送的报文段都必须把ACK置为1。 (8)推送PSH： 1bit。当两个应用进程进行交互式通信时，有时在一端的应用进程希望在键入一个命令后立即就能够收到对方的响应。在这种情况下，TCP就可以使用推送操作。这时，发送方TCP把PSH置为1，并立即创建一个报文段发送出去。接收方TCP收到PSH=1的报文段，就尽快地交付给接收应用进程，而不再等到整个缓存都填满了之后再向上交付。 (9)复位RST： 1bit。当RST=1时，表明TCP连接中出现严重差错，必须释放连接，然后再重新建立运输连接。RST置为1还用来拒绝一个非法的报文段或拒绝打开一个连接。 (10)同步SYN： 1bit。在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN=1和ACK=1。因此，SYN置为1表示这是一个连接请求或连接接收报文。 (11)终止FIN： 1bit。用来释放一个连接。当FIN=1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。 (12)窗口： 占2个字节。窗口值是0~2^16-1之间的整数。窗口指的是发送本报文段的一方的接收窗口。窗口值告诉对方：从本报文段首部中的确认号算起，接收方目前允许对方放松的数据量。窗口值作为接收方让发送方设置其发送窗口的依据。 (13)检验和： 占2个字节。检验和字段检验的范围包括首部和数据两部分。和UDP用户数据报一样，在计算检验和时，要在TCP报文段的前面加上12字节的伪首部。TCP的协议号为6， (14)紧急指针： 占2个字节。紧急指针仅在URG=1时有意义，它指出本报文段中的紧急数据的字节数，紧急指针指出了紧急数据的末尾在报文段中的位置。值得注意的是，即使窗口为0时也可放松紧急数据。 (15)选项： 长度可变，最长可达40字节。当没有使用选项时，TCP的首部长度是20字节。TCP的最大报文段长度MSS默认情况下536字节。MSS是每一个TCP报文段中的数据字段的最大长度。 TCP可靠传输的实现 以字节为单位的滑动窗口 超时重传时间的选择 选择确认SACK TCP的流量控制 利用滑动窗口实现流量控制 注意：可靠传输和流量控制是通过滑动窗口实现的，而拥塞控制是由拥塞窗口来控制的，两者切不可搞混！ TCP的拥塞控制慢开始和拥塞避免 快重传和快恢复 TCP的运输连接管理TCP三次握手 TCP四次挥手 TCP的有限状态机 为什么A在TIME-WAIT状态必须等待2MSL（最大报文段寿命，Maximum Segment Lifetime）？&emsp;&emsp;第一，为了保证A发送的最后一个ACK报文段能够到达B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认。B会超时重传这个FIN+ACK报文段，而A就能在2MSL时间内收到这个重传的FIN+ACK报文段。接着A重传一次确认，重新启动2MSL计时器。最后A和B都正常进入到CLOSED状态。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，那么就无法收到B重传的FIN+ACK报文段，因而也不会再发送一次确认报文段。这样，B就无法按照正常步骤进入CLOSED状态。 &emsp;&emsp;第二，防止“已失效的连接请求报文段”出现在本链接中。A在发送完最后一个ACK报文段后，再经过实践2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。B只要收到了A发出的确认，就进入CLOSED状态。同样，B在撤销响应的传输控制块TCB后，就结束了这次的TCP连接。 在浏览器中输入www.baidu.com后执行的全部过程1、客户端浏览器通过DNS解析到www.baidu.com的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径。客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层。 2、在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。 3、客户端的网络层不用关系应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，我不作过多的描述，无非就是通过查找路由表决定通过那个路径到达服务器。 4、客户端的链路层，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。 扩展问题DNS域名系统，简单描述其工作原理。当DNS客户机需要在程序中使用名称时，它会查询DNS服务器来解析该名称。客户机发送的每条查询信息包括三条信息：包括：指定的DNS域名，指定的查询类型，DNS域名的指定类别。基于UDP服务，端口53. 该应用一般不直接为用户使用，而是为其他应用服务，如HTTP，SMTP等在其中需要完成主机名到IP地址的转换。 面向连接和非面向连接的服务的特点是什么？面向连接的服务，通信双方在进行通信之前，要先在双方建立起一个完整的可以彼此沟通的通道，在通信过程中，整个连接的情况一直可以被实时地监控和管理。 非面向连接的服务，不需要预先建立一个联络两个通信节点的连接，需要通信的时候，发送节点就可以往网络上发送信息，让信息自主地在网络上去传，一般在传输的过程中不再加以监控。 TCP的三次握手过程？为什么会采用三次握手，若采用二次握手可以吗？答：建立连接的过程是利用客户服务器模式，假设主机A为客户端，主机B为服务器端。 （1）TCP的三次握手过程：主机A向B发送连接请求；主机B对收到的主机A的报文段进行确认；主机A再次对主机B的确认进行确认。 （2）采用三次握手是为了防止失效的连接请求报文段突然又传送到主机B，因而产生错误。失效的连接请求报文段是指：主机A发出的连接请求没有收到主机B的确认，于是经过一段时间后，主机A又重新向主机B发送连接请求，且建立成功，顺序完成数据传输。考虑这样一种特殊情况，主机A第一次发送的连接请求并没有丢失，而是因为网络节点导致延迟达到主机B，主机B以为是主机A又发起的新连接，于是主机B同意连接，并向主机A发回确认，但是此时主机A根本不会理会，主机B就一直在等待主机A发送数据，导致主机B的资源浪费。","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"record","slug":"record","permalink":"/tags/record/"},{"name":"network","slug":"network","permalink":"/tags/network/"}]},{"title":"Cookie/Session机制","date":"2017-08-19T13:14:53.000Z","path":"2017/08/19/Cookie-Session机制/","text":"&emsp;&emsp;会话（Session）跟踪是Web程序中常用的技术，用来跟踪用户的整个会话。常用的会话跟踪技术是Cookie与Session。Cookie通过在客户端记录信息确定用户身份，Session通过在服务器端记录信息确定用户身份。 Cookie在程序中，会话跟踪是很重要的事情。理论上，一个用户的所有请求操作都应该属于同一个会话，而另一个用户的所有请求操作则应该属于另一个会话，二者不能混淆。例如，用户A在超市购买的任何商品都应该放在A的购物车内，不论是用户A什么时间购买的，这都是属于同一个会话的，不能放入用户B或用户C的购物车内，这不属于同一个会话。 而Web应用程序是使用HTTP协议传输数据的。HTTP协议是无状态的协议。一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。这就意味着服务器无法从连接上跟踪会话。即用户A购买了一件商品放入购物车内，当再次购买商品时服务器已经无法判断该购买行为是属于用户A的会话还是用户B的会话了。要跟踪该会话，必须引入一种机制。 Cookie就是这样的一种机制。它可以弥补HTTP协议无状态的不足。在Session出现之前，基本上所有的网站都采用Cookie来跟踪会话。 Cookie的工作原理是给客户端们颁发一个通行证吧，每人一个，无论谁访问都必须携带自己通行证。这样服务器就能从通行证上确认客户身份了。 Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。 Cookie的类型Cookie总时由用户客户端进行保存的（一般是浏览器），按其存储位置可分为：内存式Cookie和硬盘式Cookie。 内存式Cookie存储在内存中，浏览器关闭后就会消失，由于其存储时间较短，因此也被称为非持久Cookie或会话Cookie。 硬盘式Cookie保存在硬盘中，其不会随浏览器的关闭而消失，除非用户手工清理或到了过期时间。由于硬盘式Cookie存储时间是长期的，因此也被称为持久Cookie。 Cookie的实现原理Cookie定义了一些HTTP请求头和HTTP响应头，通过这些HTTP头信息使服务器可以与客户进行状态交互。 客户端请求服务器后，如果服务器需要记录用户状态，服务器会在响应信息中包含一个Set-Cookie的响应头，客户端会根据这个响应头存储Cookie信息。再次请求服务器时，客户端会在请求信息中包含一个Cookie请求头，而服务器会根据这个请求头进行用户身份、状态等校验。 Cookie的过期时间&emsp;&emsp;Cookie的maxAge决定着Cookie的有效期，单位为秒（Second）。Cookie中通过getMaxAge()方法与setMaxAge(int maxAge)方法来读写maxAge属性。如果maxAge属性为正数，则表示该Cookie会在maxAge秒之后自动失效。浏览器会将maxAge为正数的Cookie持久化，即写到对应的Cookie文件中。无论客户关闭了浏览器还是电脑，只要还在maxAge秒之前，登录网站时该Cookie仍然有效。下面代码中的Cookie信息将永远有效。 Cookie的修改删除&emsp;&emsp;Cookie并不提供修改、删除操作。如果要修改某个Cookie，只需要新建一个同名的Cookie，添加到response中覆盖原来的Cookie。如果要删除某个Cookie，只需要新建一个同名的Cookie，并将maxAge设置为0，并添加到response中覆盖原来的Cookie。注意是0而不是负数。负数代表其他的意义。读者可以通过上例的程序进行验证，设置不同的属性。 Cookie的域名Cookie是不可跨域名的。域名www.google.com颁发的Cookie不会被提交到域名www.baidu.com去。这是由Cookie的隐私安全机制决定的。隐私安全机制能够禁止网站非法获取其他网站的Cookie。正常情况下，同一个一级域名下的两个二级域名如www.helloweenvsfei.com和images.helloweenvsfei.com也不能交互使用Cookie，因为二者的域名并不严格相同。如果想所有helloweenvsfei.com名下的二级域名都可以使用该Cookie，需要设置Cookie的domain参数。12345Cookie cookie = new Cookie(\"time\",\"20080808\"); // 新建Cookiecookie.setDomain(\".helloweenvsfei.com\"); // 设置域名cookie.setPath(\"/\"); // 设置路径cookie.setMaxAge(Integer.MAX_VALUE); // 设置有效期response.addCookie(cookie); // 输出到客户端 注意：domain参数必须以点(“.”)开始。另外，name相同但domain不同的两个Cookie是两个不同的Cookie。如果想要两个域名完全不同的网站共有Cookie，可以生成两个Cookie，domain属性分别为两个域名，输出到客户端。 Cookie的路径&emsp;&emsp;domain属性决定运行访问Cookie的域名，而path属性决定允许访问Cookie的路径（ContextPath）。例如，如果只允许/sessionWeb/下的程序使用Cookie，可以这么写：123Cookie cookie = new Cookie(\"time\",\"20080808\"); // 新建Cookiecookie.setPath(\"/session/\"); // 设置路径response.addCookie(cookie); // 输出到客户端 Cookie的安全属性&emsp;&emsp;HTTP协议不仅是无状态的，而且是不安全的。使用HTTP协议的数据不经过任何加密就直接在网络上传播，有被截获的可能。使用HTTP协议传输很机密的内容是一种隐患。如果不希望Cookie在HTTP等非安全协议中传输，可以设置Cookie的secure属性为true。浏览器只会在HTTPS和SSL等安全协议中传输此类Cookie。 Cookie对于中文编码&emsp;&emsp;中文与英文字符不同，中文属于Unicode字符，在内存中占4个字符，而英文属于ASCII字符，内存中只占2个字节。Cookie中使用Unicode字符时需要对Unicode字符进行编码，否则会乱码。 SessionSession是服务器端使用的一种记录客户端状态的机制，使用上比Cookie简单一些，相应的也增加了服务器的存储压力。 Session的含义&emsp;&emsp;Session是另一种记录客户状态的机制，不同的是Cookie保存在客户端浏览器中，而Session保存在服务器上。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。如果说Cookie机制是通过检查客户身上的“通行证”来确定客户身份的话，那么Session机制就是通过检查服务器上的“客户明细表”来确认客户身份。Session相当于程序在服务器上建立的一份客户档案，客户来访的时候只需要查询客户档案表就可以了。 Session对应的类为javax.servlet.http.HttpSession类。每个来访者对应一个Session对象，所有该客户的状态信息都保存在这个Session对象里。Session对象是在客户端第一次请求服务器的时候创建的。Session也是一种key-value的属性对，通过getAttribute(Stringkey)和setAttribute(String key，Objectvalue)方法读写客户状态信息。Session机制决定了当前客户只会获取到自己的Session，而不会获取到别人的Session。各客户的Session也彼此独立，互不可见。 Session生命周期&emsp;&emsp;Session保存在服务器端。为了获得更高的存取速度，服务器一般把Session放在内存里。每个用户都会有一个独立的Session。如果Session内容过于复杂，当大量客户访问服务器时可能会导致内存溢出。因此，Session里的信息应该尽量精简。Session在用户第一次访问服务器的时候自动创建。需要注意只有访问JSP、Servlet等程序时才会创建Session，只访问HTML、IMAGE等静态资源并不会创建Session。如果尚未生成Session，也可以使用request.getSession(true)强制生成Session。Session生成后，只要用户继续访问，服务器就会更新Session的最后访问时间，并维护该Session。用户每访问服务器一次，无论是否读写Session，服务器都认为该用户的Session“活跃（active）”了一次。 Session的有效期&emsp;&emsp;由于会有越来越多的用户访问服务器，因此Session也会越来越多。为防止内存溢出，服务器会把长时间内没有活跃的Session从内存删除。这个时间就是Session的超时时间。如果超过了超时时间没访问过服务器，Session就自动失效了。Session的超时时间为maxInactiveInterval属性，可以通过对应的getMaxInactiveInterval()获取，通过setMaxInactiveInterval(longinterval)修改。Session的超时时间也可以在web.xml中修改。另外，通过调用Session的invalidate()方法可以使Session失效。 Session对浏览器的要求&emsp;&emsp;虽然Session保存在服务器，对客户端是透明的，它的正常运行仍然需要客户端浏览器的支持。这是因为Session需要使用Cookie作为识别标志。HTTP协议是无状态的，Session不能依据HTTP连接来判断是否为同一客户，因此服务器向客户端浏览器发送一个名为JSESSIONID的Cookie，它的值为该Session的id（也就是HttpSession.getId()的返回值）。Session依据该Cookie来识别是否为同一用户。该Cookie为服务器自动生成的，它的maxAge属性一般为–1，表示仅当前浏览器内有效，并且各浏览器窗口间不共享，关闭浏览器就会失效。因此同一机器的两个浏览器窗口访问服务器时，会生成两个不同的Session。但是由浏览器窗口内的链接、脚本等打开的新窗口（也就是说不是双击桌面浏览器图标等打开的窗口）除外。这类子窗口会共享父窗口的Cookie，因此会共享一个Session。 URL地址重写&emsp;&emsp;URL地址重写是对客户端不支持Cookie的解决方案。URL地址重写的原理是将该用户Session的id信息重写到URL地址中。服务器能够解析重写后的URL获取Session的id。这样即使客户端不支持Cookie，也可以使用Session来记录用户状态。HttpServletResponse类提供了encodeURL(Stringurl)实现URL地址重写。 Session中禁止使用Cookie&emsp;&emsp;既然WAP上大部分的客户浏览器都不支持Cookie，索性禁止Session使用Cookie，统一使用URL地址重写会更好一些。Java Web规范支持通过配置的方式禁用Cookie。下面举例说一下怎样通过配置禁止使用Cookie。打开项目sessionWeb的WebRoot目录下的META-INF文件夹（跟WEB-INF文件夹同级，如果没有则创建），打开context.xml（如果没有则创建），编辑内容如下：代码1.11 /META-INF/context.xml123&lt;?xml version='1.0' encoding='UTF-8'?&gt;&lt;Context path=\"/sessionWeb\"cookies=\"false\"&gt;&lt;/Context&gt; 或者修改Tomcat全局的conf/context.xml，修改内容如下：代码1.12 context.xml1234&lt;!-- The contents of this file will be loaded for eachweb application --&gt;&lt;Context cookies=\"false\"&gt; &lt;!-- ... 中间代码略 --&gt;&lt;/Context&gt; 部署后TOMCAT便不会自动生成名JSESSIONID的Cookie，Session也不会以Cookie为识别标志，而仅仅以重写后的URL地址为识别标志了。 参考文献Http Cookie机制及Cookie的实现原理Cookie/Session机制详解","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"record","slug":"record","permalink":"/tags/record/"},{"name":"network","slug":"network","permalink":"/tags/network/"}]},{"title":"关于mina的知识整理","date":"2017-08-18T09:55:50.000Z","path":"2017/08/18/关于mina的知识整理/","text":"&emsp;&emsp;Apache MINA(Multipurpose Infrastructure for Network Applications) 是 Apache 组织一个较新的项目，它为开发高性能和高可用性的网络应用程序提供了非常便利的框架。当前发行的 MINA 版本支持基于 Java NIO 技术的 TCP/UDP 应用程序开发、串口通讯程序（只在最新的预览版中提供），MINA 所支持的功能也在进一步的扩展中。 MINA基本类的描述 IoAccepter 相当于网络应用程序中的服务器端 IoConnector 相当于客户端 IoSession 当前客户端到服务器端的一个连接实例 IoHandler 业务处理逻辑 IoFilter 过滤器用于悬接通讯层接口与业务层接口 在上图中的模块链中，IoService 便是应用程序的入口，相当于我们前面代码中的 IoAccepter，IoAccepter 便是 IoService 的一个扩展接口。IoService 接口可以用来添加多个 IoFilter，这些 IoFilter 符合责任链模式并由 IoProcessor 线程负责调用。而 IoAccepter 在 ioService 接口的基础上还提供绑定某个通讯端口以及取消绑定的接口。IoAccepter 的：IoAcceptor acceptor = new SocketAcceptor();相当于我们使用了 Socket 通讯方式作为服务的接入，当前版本的 MINA 还提供了除 SocketAccepter 外的基于数据报文通讯的 DatagramAccepter 以及基于管道通讯的 VmPipeAccepter。而在上图中最右端也就是 IoHandler，这便是业务处理模块。编写 Handler 类就是使用 MINA 开发网络应用程序的重心所在，相当于 MINA 已经帮你处理了所有的通讯方面的细节问题。为了简化 Handler 类，MINA 提供了 IoHandlerAdapter 类，此类仅仅是实现了 IoHandler 接口，但并不做任何处理。 前面我们提到 IoService 是负责底层通讯接入，而 IoHandler 是负责业务处理的。那么 MINA 架构图中的 IoFilter 作何用途呢？答案是你想作何用途都可以。但是有一个用途却是必须的，那就是作为 IoService 和 IoHandler 之间的桥梁。IoHandler 接口中最重要的一个方法是 messageReceived，这个方法的第二个参数是一个 Object 型的消息，总所周知，Object 是所有 Java 对象的基础，那到底谁来决定这个消息到底是什么类型呢？答案也就在这个 IoFilter 中。在前面使用的例子中，我们添加了一个 IoFilter 是 new ProtocolCodecFilter(new TextLineCodecFactory())，这个过滤器的作用是将来自客户端输入的信息转换成一行行的文本后传递给 IoHandler，因此我们可以在 messageReceived 中直接将 msg 对象强制转换成 String 对象。 而如果我们不提供任何过滤器的话，那么在 messageReceived 方法中的第二个参数类型就是一个 byte 的缓冲区，对应的类是 org.apache.mina.common.ByteBuffer。虽然你也可以将解析客户端信息放在 IoHandler 中来做，但这并不是推荐的做法，使原来清晰的模型又模糊起来，变得 IoHandler 不只是业务处理，还得充当协议解析的任务。 NIO的模式Reactor模型&emsp;&emsp;无论是C++还是Java编写的网络框架，大多数都是基于Reactor模式进行设计和开发，Reactor模式基于事件驱动，特别适合处理海量的I/O事件。 单线程模型Reactor单线程模型，指的是所有的IO操作都在同一个NIO线程上面完成，NIO线程的职责如下： 1）作为NIO服务端，接收客户端的TCP连接； 2）作为NIO客户端，向服务端发起TCP连接； 3）读取通信对端的请求或者应答消息； 4）向通信对端发送消息请求或者应答消息。 &emsp;&emsp;由于Reactor模式使用的是异步非阻塞IO，所有的IO操作都不会导致阻塞，理论上一个线程可以独立处理所有IO相关的操作。从架构层面看，一个NIO线程确实可以完成其承担的职责。例如，通过Acceptor类接收客户端的TCP连接请求消息，链路建立成功之后，通过Dispatch将对应的ByteBuffer派发到指定的Handler上进行消息解码。用户线程可以通过消息编码通过NIO线程将消息发送给客户端。 对于一些小容量应用场景，可以使用单线程模型。但是对于高负载、大并发的应用场景却不合适，主要原因如下： 1）一个NIO线程同时处理成百上千的链路，性能上无法支撑，即便NIO线程的CPU负荷达到100%，也无法满足海量消息的编码、解码、读取和发送； 2）当NIO线程负载过重之后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往会进行重发，这更加重了NIO线程的负载，最终会导致大量消息积压和处理超时，成为系统的性能瓶颈； 3）可靠性问题：一旦NIO线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。 多线程模型&emsp;&emsp;Rector多线程模型与单线程模型最大的区别就是有一组NIO线程处理IO操作，它的原理图如下： 1）有专门一个NIO线程-Acceptor线程用于监听服务端，接收客户端的TCP连接请求； 2）网络IO操作-读、写等由一个NIO线程池负责，线程池可以采用标准的JDK线程池实现，它包含一个任务队列和N个可用的线程，由这些NIO线程负责消息的读取、解码、编码和发送； 3）1个NIO线程可以同时处理N条链路，但是1个链路只对应1个NIO线程，防止发生并发操作问题 在绝大多数场景下，Reactor多线程模型都可以满足性能需求；但是，在极个别特殊场景中，一个NIO线程负责监听和处理所有的客户端连接可能会存在性能问题。例如并发百万客户端连接，或者服务端需要对客户端握手进行安全认证，但是认证本身非常损耗性能。在这类场景下，单独一个Acceptor线程可能会存在性能不足问题，为了解决性能问题，产生了第三种Reactor线程模型-主从Reactor多线程模型。 主从多线程模型&emsp;&emsp;主从Reactor线程模型的特点是：服务端用于接收客户端连接的不再是个1个单独的NIO线程，而是一个独立的NIO线程池。Acceptor接收到客户端TCP连接请求处理完成后（可能包含接入认证等），将新创建的SocketChannel注册到IO线程池（sub reactor线程池）的某个IO线程上，由它负责SocketChannel的读写和编解码工作。Acceptor线程池仅仅只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端subReactor线程池的IO线程上，由IO线程负责后续的IO操作。 利用主从NIO线程模型，可以解决1个服务端监听线程无法有效处理所有客户端连接的性能不足问题。 它的工作流程总结如下： 从主线程池中随机选择一个Reactor线程作为Acceptor线程，用于绑定监听端口，接收客户端连接；Acceptor线程接收客户端连接请求之后创建新的SocketChannel，将其注册到主线程池的其它Reactor线程上，由其负责接入认证、IP黑白名单过滤、握手等操作；步骤2完成之后，业务层的链路正式建立，将SocketChannel从主线程池的Reactor线程的多路复用器上摘除，重新注册到Sub线程池的线程上，用于处理I/O的读写操作。 MINA中常用的接口IoService这个接口是服务端IoAcceptor、客户端IoConnector 的抽象，提供IO 服务和管理IoSession的功能，它有如下几个常用的方法：A. TransportMetadata getTransportMetadata()：这个方法获取传输方式的元数据描述信息，也就是底层到底基于什么的实现，譬如：nio、apr 等。B. void addListener(IoServiceListener listener)：这个方法可以为IoService 增加一个监听器，用于监听IoService 的创建、活动、失效、空闲、销毁，具体可以参考IoServiceListener 接口中的方法，这为你参与IoService 的生命周期提供了机会。C. void removeListener(IoServiceListener listener)：这个方法用于移除上面的方法添加的监听器。D. void setHandler(IoHandler handler)：这个方法用于向IoService 注册IoHandler，同时有getHandler()方法获取Handler。E. Map&lt;Long,IoSession&gt; getManagedSessions()：这个方法获取IoService 上管理的所有IoSession，Map 的key 是IoSession 的id。F. IoSessionConfig getSessionConfig()：这个方法用于获取IoSession 的配置对象，通过IoSessionConfig 对象可以设置Socket 连接的一些选项。 IoAcceptor这个接口是TCPServer 的接口，主要增加了void bind()监听端口、void unbind()解除对套接字的监听等方法。这里与传统的JAVA 中的ServerSocket 不同的是IoAcceptor 可以多次调用bind()方法（或者在一个方法中传入多个SocketAddress 参数）同时监听多个端口。 IoConnector这个接口是TCPClient 的接口， 主要增加了ConnectFuture connect(SocketAddressremoteAddress,SocketAddress localAddress)方法，用于与Server 端建立连接，第二个参数如果不传递则使用本地的一个随机端口访问Server 端。这个方法是异步执行的，同样的，也可以同时连接多个服务端。 IoSession这个接口用于表示Server 端与Client 端的连接，IoAcceptor.accept()的时候返回实例。这个接口有如下常用的方法：A. WriteFuture write(Object message)：这个方法用于写数据，该操作是异步的。B. CloseFuture close(boolean immediately)：这个方法用于关闭IoSession，该操作也是异步的，参数指定true 表示立即关闭，否则就在所有的写操作都flush 之后再关闭。C. Object setAttribute(Object key,Object value)：这个方法用于给我们向会话中添加一些属性，这样可以在会话过程中都可以使用，类似于HttpSession 的setAttrbute()方法。IoSession 内部使用同步的HashMap 存储你添加的自定义属性。D. SocketAddress getRemoteAddress()：这个方法获取远端连接的套接字地址。E. void suspendWrite()：这个方法用于挂起写操作，那么有void resumeWrite()方法与之配对。对于read()方法同样适用。F. ReadFuture read()：这个方法用于读取数据， 但默认是不能使用的， 你需要调用IoSessionConfig 的setUseReadOperation(true)才可以使用这个异步读取的方法。一般我们不会用到这个方法，因为这个方法的内部实现是将数据保存到一个BlockingQueue，假如是Server 端，因为大量的Client 端发送的数据在Server 端都这么读取，那么可能会导致内存泄漏，但对于Client，可能有的时候会比较便利。G. IoService getService()：这个方法返回与当前会话对象关联的IoService 实例。关于TCP连接的关闭：无论在客户端还是服务端，IoSession 都用于表示底层的一个TCP 连接，那么你会发现无论是Server 端还是Client 端的IoSession 调用close()方法之后，TCP 连接虽然显示关闭， 但主线程仍然在运行，也就是JVM 并未退出，这是因为IoSession 的close()仅仅是关闭了TCP的连接通道，并没有关闭Server 端、Client 端的程序。你需要调用IoService 的dispose()方法停止Server 端、Client 端。 IoSessionConfig这个方法用于指定此次会话的配置，它有如下常用的方法：A. void setReadBufferSize(int size)： 这个方法设置读取缓冲的字节数，但一般不需要调用这个方法，因为IoProcessor 会自动调整缓冲的大小。你可以调用setMinReadBufferSize()、setMaxReadBufferSize()方法，这样无论IoProcessor 无论如何自动调整，都会在你指定的区间。B. void setIdleTime(IdleStatus status,int idleTime)：这个方法设置关联在通道上的读、写或者是读写事件在指定时间内未发生，该通道就进入空闲状态。一旦调用这个方法，则每隔idleTime 都会回调过滤器、IoHandler 中的sessionIdle()方法。C. void setWriteTimeout(int time)：这个方法设置写操作的超时时间。D. void setUseReadOperation(boolean useReadOperation)：这个方法设置IoSession 的read()方法是否可用，默认是false。 IoHandler这个接口是你编写业务逻辑的地方，从上面的示例代码可以看出，读取数据、发送数据基本都在这个接口总完成，这个实例是绑定到IoService 上的，有且只有一个实例（没有给一个IoService 注入一个IoHandler 实例会抛出异常）。它有如下几个方法：A. void sessionCreated(IoSession session)：这个方法当一个Session 对象被创建的时候被调用。对于TCP 连接来说，连接被接受的时候调用，但要注意此时TCP 连接并未建立，此方法仅代表字面含义，也就是连接的对象IoSession 被创建完毕的时候，回调这个方法。对于UDP 来说，当有数据包收到的时候回调这个方法，因为UDP 是无连接的。B. void sessionOpened(IoSession session)：这个方法在连接被打开时调用，它总是在sessionCreated()方法之后被调用。对于TCP 来说，它是在连接被建立之后调用，你可以在这里执行一些认证操作、发送数据等。对于UDP 来说，这个方法与sessionCreated()没什么区别，但是紧跟其后执行。如果你每隔一段时间，发送一些数据，那么sessionCreated()方法只会在第一次调用，但是sessionOpened()方法每次都会调用。C. void sessionClosed(IoSession session) ：对于TCP 来说，连接被关闭时，调用这个方法。对于UDP 来说，IoSession 的close()方法被调用时才会毁掉这个方法。D. void sessionIdle(IoSession session, IdleStatus status) ：这个方法在IoSession 的通道进入空闲状态时调用，对于UDP 协议来说，这个方法始终不会被调用。E. void exceptionCaught(IoSession session, Throwable cause) ：这个方法在你的程序、Mina 自身出现异常时回调，一般这里是关闭IoSession。 F. void messageReceived(IoSession session, Object message) ：接收到消息时调用的方法，也就是用于接收消息的方法，一般情况下，message 是一个IoBuffer 类，如果你使用了协议编解码器，那么可以强制转换为你需要的类型。通常我们都是会使用协议编解码器的， 就像上面的例子， 因为协议编解码器是TextLineCodecFactory，所以我们可以强制转message 为String 类型。G. void messageSent(IoSession session, Object message) ：当发送消息成功时调用这个方法，注意这里的措辞，发送成功之后，也就是说发送消息是不能用这个方法的。发送消息的时机：发送消息应该在sessionOpened()、messageReceived()方法中调用IoSession.write()方法完成。因为在sessionOpened()方法中，TCP 连接已经真正打开，同样的在messageReceived()方法TCP 连接也是打开状态，只不过两者的时机不同。sessionOpened()方法是在TCP 连接建立之后，接收到数据之前发送；messageReceived()方法是在接收到数据之后发送，你可以完成依据收到的内容是什么样子，决定发送什么样的数据。因为这个接口中的方法太多，因此通常使用适配器模式IoHandlerAdapter，覆盖你所感兴趣的方法即可。 IoFuture在Mina 的很多操作中，你会看到返回值是XXXFuture，实际上他们都是IoFuture 的子类，看到这样的返回值，这个方法就说明是异步执行的，主要的子类有ConnectFuture、CloseFuture 、ReadFuture 、WriteFuture 。这个接口的大部分操作都和java.util.concurrent.Future 接口是类似的，譬如：await()、awaitUninterruptibly()等，一般我们常用awaitUninterruptibly()方法可以等待异步执行的结果返回。这个接口有如下常用的方法：A. IoFuture addListener(IoFutureListener&lt;?&gt; listener)：这个方法用于添加一个监听器， 在异步执行的结果返回时监听器中的回调方法operationComplete(IoFuture future)，也就是说，这是替代awaitUninterruptibly()方法另一种等待异步执行结果的方法，它的好处是不会产生阻塞。B. IoFuture removeListener(IoFutureListener&lt;?&gt; listener)：这个方法用于移除指定的监听器。C. IoSession getSession()：这个方法返回当前的IoSession。举个例子，我们在客户端调用connect()方法访问Server 端的时候，实际上这就是一个异步执行的方法，也就是调用connect()方法之后立即返回，执行下面的代码，而不管是否连接成功。 Mina中自带的解码器Mina中自带的解码器： CumulativeProtocolDecoder累积性解码器 SynchronizedProtocolDecoder 这个解码器用于将任何一个解码器包装为一个线程安全的解码器，用于解决上面说的每次执行decode()方法时可能线程不是上一次的线程的问题，但这样会在高并发时，大大降低系统的性能。 TextLineDecoder按照文本的换行符（ Windows:/r/n 、Linux:/n、Mac:/r）解码数据。 PrefixedStringDecoder 这个类继承自CumulativeProtocolDecoder类，用于读取数据最前端的1、2、4 个字节表示后面的数据长度的数据。譬如：一个段数据的前两个字节表示后面的真实数据的长度，那么你就可以用这个方法进行解码。 编码器解码器的编写有以下几个步骤：A. 将 encode()方法中的message 对象强制转换为指定的对象类型；B. 创建IoBuffer 缓冲区对象，并设置为自动扩展；C. 将转换后的message 对象中的各个部分按照指定的应用层协议进行组装，并put()到IoBuffer 缓冲区；D. 当你组装数据完毕之后，调用flip()方法，为输出做好准备，切记在write()方法之前，要调用IoBuffer 的flip()方法，否则缓冲区的position 的后面是没有数据可以用来输出的，你必须调用flip()方法将position 移至0，limit 移至刚才的position。这个flip()方法的含义请参看java.nio.ByteBuffer。E. 最后调用ProtocolEncoderOutput 的write()方法输出IoBuffer 缓冲区实例。 解码器在Mina 中编写解码器，可以实现ProtocolDecoder 接口，其中有decode()、finishDecode()、dispose()三个方法。这里的finishDecode()方法可以用于处理在IoSession 关闭时剩余的未读取数据，一般这个方法并不会被使用到，除非协议中未定义任何标识数据什么时候截止的约定，譬如：Http 响应的Content-Length 未设定，那么在你认为读取完数据后，关闭TCP连接（IoSession 的关闭）后，就可以调用这个方法处理剩余的数据，当然你也可以忽略调剩余的数据。同样的，一般情况下，我们只需要继承适配器ProtocolDecoderAdapter，关注decode()方法即可。但前面说过解码器相对编码器来说，最麻烦的是数据发送过来的规模，以聊天室为例，一个TCP 连接建立之后，那么隔一段时间就会有聊天内容发送过来，也就是decode()方法会被往复调用，这样处理起来就会非常麻烦。那么Mina 中幸好提供了CumulativeProtocolDecoder类，从名字上可以看出累积性的协议解码器，也就是说只要有数据发送过来，这个类就会去读取数据，然后累积到内部的IoBuffer 缓冲区，但是具体的拆包（把累积到缓冲区的数据解码为JAVA 对象）交由子类的doDecode()方法完成，实际上CumulativeProtocolDecoder就是在decode()反复的调用暴漏给子类实现的doDecode()方法。 解码的具体执行过程A. 你的doDecode()方法返回true 时，CumulativeProtocolDecoder 的decode()方法会首先判断你是否在doDecode()方法中从内部的IoBuffer 缓冲区读取了数据，如果没有，则会抛出非法的状态异常，也就是你的doDecode()方法返回true 就表示你已经消费了本次数据（相当于聊天室中一个完整的消息已经读取完毕），进一步说，也就是此时你必须已经消费过内部的IoBuffer 缓冲区的数据（哪怕是消费了一个字节的数据）。如果验证过通过，那么CumulativeProtocolDecoder 会检查缓冲区内是否还有数据未读取，如果有就继续调用doDecode()方法，没有就停止对doDecode()方法的调用，直到有新的数据被缓冲。 B. 当你的doDecode()方法返回false 时，CumulativeProtocolDecoder 会停止对doDecode()方法的调用，但此时如果本次数据还有未读取完的，就将含有剩余数据的IoBuffer 缓冲区保存到IoSession 中，以便下一次数据到来时可以从IoSession 中提取合并。如果发现本次数据全都读取完毕，则清空IoBuffer 缓冲区。 简而言之，当你认为读取到的数据已经够解码了，那么就返回true，否则就返回false。这个CumulativeProtocolDecoder 其实最重要的工作就是帮你完成了数据的累积，因为这个工作是很烦琐的。 参考文献 使用 Apache MINA 开发高性能网络应用程序 mina框架详解 Netty系列之Netty线程模型","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"record","slug":"record","permalink":"/tags/record/"},{"name":"network","slug":"network","permalink":"/tags/network/"}]},{"title":"HttpEntity出现的java.io.IOException:Stream Closed","date":"2017-08-18T02:24:18.000Z","path":"2017/08/18/HttpEntity出现的java-io-IOException-Stream-Closed/","text":"&emsp;&emsp;最近在开发调试过程中出现了一个java.io.IOException:Stream Closed的错误，而这个错误隐藏的比较好，因为它不涉及到主要的流程，只是在通知邮件的时候出现了这么一个异常，所以直到测试人员介入的时候才发现了这一个隐藏的IOException。 下面就来看看这个异常是怎么产生的：1234567891011121314151617181920212223242526272829303132for (int i = 0; i &lt; batch; i++) &#123; List&lt;HashMap&lt;String, String&gt;&gt; sub = performances.subList(100 * i, Math.min(100 * (i + 1), performances.size())); HashMap&lt;String, Object&gt; json = new HashMap&lt;&gt;(); json.put(\"userId\", user); json.put(\"sign\", sign); json.put(\"type\", \"year\"); json.put(\"list\", sub); CloseableHttpResponse response = null; try &#123; response = HttpClientUtil.postJson(url, JSON.toJSONString(json), 30 * 1000, 30 * 1000, 30 * 1000); if (response != null &amp;&amp; response.getStatusLine().getStatusCode() == HttpStatus.SC_OK) &#123; JSONObject jsonObject = JSON.parseObject(EntityUtils.toString(response.getEntity(), Charset.forName(\"UTF-8\"))); String code = jsonObject.getString(\"code\"); List&lt;Integer&gt; subIds = ids.subList(100 * i, Math.min(100 * (i + 1), performances.size())); if (!\"200\".equals(code)) &#123; sendFailMail(subIds, \"\",返回code非200\",response != null ? EntityUtils.toString(response.getEntity(), Charset.forName(\"UTF-8\")) : \"空\"); &#125; &#125; else &#123; List&lt;Integer&gt; subIds = ids.subList(100 * i, Math.min(100 * (i + 1), performances.size())); sendFailMail(subIds, \"\",response != null ? EntityUtils.toString(response.getEntity(), Charset.forName(\"UTF-8\")) : \"空\"); &#125; &#125; catch (Exception e) &#123; log.error(\"\", e); List&lt;Integer&gt; subIds = ids.subList(100 * i, Math.min(100 * (i + 1), performances.size())); sendFailMail(subIds, \"\", response != null ? EntityUtils.toString(response.getEntity(), Charset.forName(\"UTF-8\")) : \"空\"); throw e; &#125; finally &#123; if (response != null) &#123; response.close(); &#125; &#125;&#125; 当通过打断点进行定位的时候发现这个异常出现在这个循环体中，再进一步定位发现问题出现在：1234if (!\"200\".equals(code)) &#123;sendFailMail(subIds, \"\",返回code非200\",response != null ? EntityUtils.toString(response.getEntity(), Charset.forName(\"UTF-8\")) : \"空\");&#125; 于是进入到EntityUtils.toString(response.getEntity(), Charset.forName(“UTF-8”))这个方法中去看EntityUtils方法的实现,这是httpcore-4.4.4.jar的下org.apache.http.util.EntityUtils.class方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public static String toString(HttpEntity entity, Charset defaultCharset) throws IOException, ParseException &#123; Args.notNull(entity, \"Entity\"); InputStream instream = entity.getContent(); if(instream == null) &#123; return null; &#125; else &#123; try &#123; Args.check(entity.getContentLength() &lt;= 2147483647L, \"HTTP entity too large to be buffered in memory\"); int i = (int)entity.getContentLength(); if(i &lt; 0) &#123; i = 4096; &#125; Charset charset = null; try &#123; ContentType contentType = ContentType.get(entity); if(contentType != null) &#123; charset = contentType.getCharset(); &#125; &#125; catch (UnsupportedCharsetException var13) &#123; if(defaultCharset == null) &#123; throw new UnsupportedEncodingException(var13.getMessage()); &#125; &#125; if(charset == null) &#123; charset = defaultCharset; &#125; if(charset == null) &#123; charset = HTTP.DEF_CONTENT_CHARSET; &#125; Reader reader = new InputStreamReader(instream, charset); CharArrayBuffer buffer = new CharArrayBuffer(i); char[] tmp = new char[1024]; int l; while((l = reader.read(tmp)) != -1) &#123; buffer.append(tmp, 0, l); &#125; String var9 = buffer.toString(); return var9; &#125; finally &#123; instream.close(); &#125; &#125; &#125; 可以看出确实是在这个方法中会抛出IOException，而且问题应该就出现在finally方法块的instream.close()上，既然改不了httpcore-4.4.4.jar下的文件，那么肯定是原先的代码中调用的方式不对。 回到源代码中发现这个方法在1JSONObject jsonObject = JSON.parseObject(EntityUtils.toString(response.getEntity(), Charset.forName(\"UTF-8\"))); 调用过一次，而在1234if (!\"200\".equals(code)) &#123;sendFailMail(subIds, \"\",返回code非200\",response != null ? EntityUtils.toString(response.getEntity(), Charset.forName(\"UTF-8\")) : \"空\");&#125; 又调用了一次。 接着去网上搜索了一下HttpEntity的这个方法 HttpEntity Apache HttpCore 4.4.6 API 在getContent()方法下有这么一句话Returns a content stream of the entity. Repeatable entities are expected to create a new instance of InputStream for each invocation of this method and therefore can be consumed multiple times. Entities that are not repeatable are expected to return the same InputStream instance and therefore may not be consumed more than once. 翻译过来的含义是getContent()方法会返回内容流的一个实体。一个entity可以重复也就意味着通过调用这个方法创建一个新的读入流实例，它的content可以被多次读取，但如果一个entity不可重复，那么它通过调用这个方法只会返回同一个读入流实例，也不能被读取多次。 在这里response.getEntity()方法获得的entity是不可重复的，因此在调用了两次EntityUtils.toString()方法后会出现StreamClosed的错误。 改写后的代码如下,即可避免java.io.IOException:Stream Closed这个异常： 123456789101112131415161718192021222324252627282930313233for (int i = 0; i &lt; batch; i++) &#123; List&lt;HashMap&lt;String, String&gt;&gt; sub = performances.subList(100 * i, Math.min(100 * (i + 1), performances.size())); HashMap&lt;String, Object&gt; json = new HashMap&lt;&gt;(); json.put(\"userId\", user); json.put(\"sign\", sign); json.put(\"type\", \"year\"); json.put(\"list\", sub); CloseableHttpResponse response = null; try &#123; response = HttpClientUtil.postJson(url, JSON.toJSONString(json), 30 * 1000, 30 * 1000, 30 * 1000); if (response != null &amp;&amp; response.getStatusLine().getStatusCode() == HttpStatus.SC_OK) &#123; String temp = EntityUtils.toString(response.getEntity(), Charset.forName(\"UTF-8\")); JSONObject jsonObject = JSON.parseObject(temp); String code = jsonObject.getString(\"code\"); List&lt;Integer&gt; subIds = ids.subList(100 * i, Math.min(100 * (i + 1), performances.size())); if (!\"200\".equals(code)) &#123; sendFailMail(subIds, \"\",返回code非200\",response != null ? temp : \"空\"); &#125; &#125; else &#123; List&lt;Integer&gt; subIds = ids.subList(100 * i, Math.min(100 * (i + 1), performances.size())); sendFailMail(subIds, \"\",response != null ? EntityUtils.toString(response.getEntity(), Charset.forName(\"UTF-8\")) : \"空\"); &#125; &#125; catch (Exception e) &#123; log.error(\"\", e); List&lt;Integer&gt; subIds = ids.subList(100 * i, Math.min(100 * (i + 1), performances.size())); sendFailMail(subIds, \"\", response != null ? EntityUtils.toString(response.getEntity(), Charset.forName(\"UTF-8\")) : \"空\"); throw e; &#125; finally &#123; if (response != null) &#123; response.close(); &#125; &#125;&#125;","categories":[{"name":"日常点滴","slug":"日常点滴","permalink":"/categories/日常点滴/"}],"tags":[{"name":"fix bug","slug":"fix-bug","permalink":"/tags/fix-bug/"}]},{"title":"数据库连接池","date":"2017-08-16T02:46:45.000Z","path":"2017/08/16/数据库连接池/","text":"使用连接池可帮助您降低连接管理开销并减少数据访问的开发任务。每当应用程序尝试访问后端存储器（例如数据库）时，它需要资源以创建、维护和释放与该数据库的连接。为了减轻此过程对整体应用程序资源的影响，应用程序服务器允许管理员在应用程序服务器上建立可以由应用程序共享的后端连接池。连接池在数个用户请求之间分布连接开销，从而节省了应用程序资源以供将来的请求使用。应用程序服务器支持用于连接池和连接重用的 JDBC 4.0 API。使用连接池指导应用程序中 JDBC 调用，指导企业 bean 使用数据库。 使用连接池的好处&emsp;&emsp;连接池可改进任何需要连接的应用程序（特别是基于 Web 的应用程序）的响应时间。当用户通过 Web 对资源发出请求时，该资源将访问数据源。由于用户频繁地与因特网上的应用程序建立连接和断开连接，所以应用程序的数据访问请求量可能会相当大。因此，对于基于 Web 的应用程序数据存储器总开销会迅速增大，性能随之下降。但是，使用连接池功能时，Web 应用程序的性能相对于正常结果可以提高达 20 倍。&emsp;&emsp;借助连接池，大多数用户请求不会引起创建新连接的开销，因为数据源能找出并使用连接池中的现有连接。当请求得到满足，并将响应返回到用户时，该资源会将连接返回到连接池以供再次使用。这就避免了断开连接造成的开销。每个用户请求都有一些连接或断开连接的开销。使用初始资源在池中产生连接后，由于能重用现有连接，因此其他开销并不大。 何时使用连接池在符合任何以下条件的应用程序中使用连接池：1、它不能忍受每次使用连接时获取连接和释放连接的开销。2、它需要应用程序服务器中的 Java 事务 API (JTA) 事务。3、它需要在相同事务中的多个用户之间共享连接。4、它需要利用产品功能部件来管理应用程序服务器中的局部事务。5、它不管理其自己连接的池。6、它不管理创建连接的细节（如数据库名称、用户名或密码） 数据库连接池的优点1、资源重用2、更快的系统响应速度3、新的资源分配手段4、统一的连接管理，避免数据库连接泄漏 常用的开源连接池DBCP数据源DBCP 是 Apache 软件基金组织下的开源连接池实现，使用DBCP，需要如下两个 jar 文件（commons-dbcp-1.4.jar和commons-pool-1.5.6.jar）：Tomcat 的连接池也是采用该连接池来实现的。该数据库连接池既可以与应用服务器整合使用，也可由应用程序独立使用。 C3P0C3P0是一个开源的JDBC连接池，它实现了数据源和JNDI绑定，支持JDBC3规范和JDBC2的标准扩展。目前使用它的开源项目有Hibernate，Spring等。C3P0数据源在项目开发中使用得比较多。 c3p0与dbcp区别1、dbcp没有自动回收空闲连接的功能2、c3p0有自动回收空闲连接功能需要导入jar：c3p0-0.9.5.1.jar和mchange-commons-java-0.2.10.jar在类目录下加入C3P0的配置文件：c3p0-config.xml jdbcUtilscommons-dbutils 是 Apache 组织提供的一个开源 JDBC工具类库，它是对JDBC的简单封装，学习成本极低，并且使用dbutils能极大简化jdbc编码的工作量，同时也不会影响程序的性能。","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"record","slug":"record","permalink":"/tags/record/"}]},{"title":"网易秋招笔试题","date":"2017-08-14T11:03:32.000Z","path":"2017/08/14/网易秋招笔试题/","text":"独立的小易小易为了向他的父母表现他已经长大独立了,他决定搬出去自己居住一段时间。一个人生活增加了许多花费: 小易每天必须吃一个水果并且需要每天支付x元的房屋租金。当前小易手中已经有f个水果和d元钱,小易也能去商店购买一些水果,商店每个水果售卖p元。小易为了表现他独立生活的能力,希望能独立生活的时间越长越好,小易希望你来帮他计算一下他最多能独立生活多少天。输入描述:输入包括一行,四个整数x, f, d, p(1 ≤ x,f,d,p ≤ 2 * 10^9),以空格分割 输入例子1:13 5 100 10 输出例子1:11 解题思路：首先在有水果的情况下，先消耗水果，此时小易只需要支付房租的费用就行；而当水果吃完后，每一天的消耗费用为(x+p)元，所以直接拿剩余的钱d去除以(x+p)就行了。（这里提示了四个整数都小于2*10^9，且之间没有相乘关系，所以int不会越界，但是如果房租x和水果数f较多时，可能会出现超时的情况） 通过代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.*;public class Main &#123; public static void main(String []args) &#123; int a[] = new int[4]; Scanner sc = new Scanner(System.in); a[0]=sc.nextInt(); a[1]=sc.nextInt(); a[2]=sc.nextInt(); a[3]=sc.nextInt(); int day = 0; if(a[2]&gt;=a[0]*a[1]) &#123; a[2]=a[2]-a[0]*a[1]; day=a[1]; a[1]=0; &#125; while(a[2]&gt;=0) &#123; if(a[1]&gt;0) &#123; a[2]-=a[0]; a[1]--; if(a[2]&lt;0) &#123; break; &#125; day++; &#125; else &#123; int res = (a[2]/(a[0]+a[3])); day = day+ res; break; &#125; &#125; System.out.println(day); &#125;&#125; 官方解答：12345678910111213141516#include &lt;bits/stdc++.h&gt;using namespace std;int x, f, d, p;int solve(int x, int f, int d, int p) &#123; int tmp1 = d / x; if(tmp1 &lt;= f) return tmp1; d -= f * x; return f + d / (x + p);&#125;int main() &#123; cin &gt;&gt; x &gt;&gt; f &gt;&gt; d &gt;&gt; p; cout &lt;&lt; solve(x, f, d, p) &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"programing","slug":"programing","permalink":"/tags/programing/"}]},{"title":"JVM梳理","date":"2017-08-09T03:33:17.000Z","path":"2017/08/09/JVM/","text":"​ 在JAVA中，有一句口号我们众所周知，“一次编写，到处运行”。而支持JAVA这种特性的关键之处在于JAVA虚拟机和字节码存储格式，JAVA虚拟机不与JAVA变成语言捆绑，只与Class文件所关联。 正因为JAVA只与Class文件相关，它不关心Class的来源，所以虚拟机对Class文件的格式有着十分严格的定义，以便进行Class的合法性等的验证。而Class文件需要被JAVA虚拟机加载，才能最终被虚拟机执行。 类的生命周期类从被加载到虚拟机到卸载出内存，它的整个生命周期有：加载、验证、准备、解析、初始化、使用、卸载。其中验证、准备和解析这3个部分统称为连接。 从类加载的原则上来说，类的生命周期一般是按照这个顺序来的，这里我们重点来看看加载、验证、准备、解析和初始化这5个过程，这5个过程是类在使用之前会完成。下面我们重点来介绍一下类不同生命周期的具体过程。 加载在加载阶段，虚拟机要完成以下3件事情： 获取类定义的二级制流（通过类的全限定名来获取） 将二级制流所代表的静态存储结构转化为方法去的运行时数据结构 在内存中生成一个代表该类的java.lang.Class对象 验证​验证是连接阶段的第一步，这一阶段的目的主要是为了验证Class文件的正确性，JAVA虚拟机对Class文件的来源并没有要求，甚至我们可以用文本编辑器来编写Class文件，所以验证是非常有必要的，验证是否严谨，直接关系虚拟机最终运行的正确性。 ​验证阶段主要包括对Class文件格式的验证、元数据的验证、字节码的验证以及符号引用的验证。 准备准备阶段是开始为类变量进行内存分配并设置变量的初始值。这里说明一下类变量是指被static修饰的变量，而不包含实例变量。 这里的类变量的初始化时在方法区中进行内存分配，而不是在堆中进行的。这里说的变量的初始值，是指设置成零值。 1public static int value = 100; //在类变量初始化阶段，value的值为0，而不是100 当然，变量被设置成零值，也不是绝对的，如果该类变量是常量的话，则会直接设置成常量值。 解析解析阶段是虚拟机将常量池内的符号引用替换成直接引用的过程。 初始化类的初始化是类加载过程的最后一步，在准备阶段，类变量已经进行了初始化，在初始化阶段，虚拟机会根据程序来初始化类变量和其他资源。 类加载器类加载器是用于实现类的加载动作，在JAVA中，类的唯一性是由类和加载该类的加载器一同唯一决定的。每一个类加载器，都拥有一个独立的类名称空间。所以简单的来说，如果两个类相等，只有在这两个类是由同一个类加载器加载的前提下有成立。 双亲委派模型从JAVA虚拟机的角度来说，存在两种不同的类加载器：启动类加载器和其他类加载器。启动类加载器是由C++来实现的，是虚拟机的一部分；而其他类加载器则有JAVA来实现，独立于虚拟机，且继承自java.lang.ClassLoader。 从开发者的角度来看，JAVA程序一般使用下面3中类加载器：启动类加载器，扩展类加载器、应用程序类加载器。 启动类加载器（Bootstrap ClassLoader）：该类负责加载\\lib目录中的，并且被虚拟机识别的类库。 扩展类加载器（Extension ClassLoader）：该类负责加载\\lib\\ext目录中的类库。 应用程序类加载器（Application ClassLoader)：该类负责加载用户类路径上所指定的类库。 ​ 我们的应用程序一般都是由这3种类加载器加载的，当然，如果有必要，我们也可以加入自己定义的类加载器。而这3种类的层次关系我们称为双亲委派模型。该模型除了顶层的启动类加载器外，其余的类加载器都有自己的父类加载器。 工作过程 当一个类加载器收到了类加载请求的时候，它会首先委派给父类加载器去完成，而每一个加载器都会如此执行，只有当父类加载器无法完成类加载的时候，子加载器才会尝试自己去加载。使用双亲委派模型的一个好处是Java类会随着类加载机制具备了一种优先级的层级关系。","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"record","slug":"record","permalink":"/tags/record/"}]},{"title":"OAuth浅析","date":"2017-08-07T07:56:13.000Z","path":"2017/08/07/OAuth浅析/","text":"&emsp;&emsp;OAuth是一个开放标准。它允许第三方网站在用户授权的前提下访问用户在服务商那里存储的信息。例如我们微信登录后通过一些链接访问其他的应用，例如大众点评，它会提示是否通过微信授权访问，如果用户确认ok，则大众点评的app就可以拿到微信中的账户信息甚至联系人列表等信息。这种授权无需将用户提供用户名和密码提供给该第三方网站。OAuth允许用户提供一个令牌给第三方网站，一个令牌对应一个特定的第三方网站，同时该令牌只能在特定的时间内访问特定的资源。 OAuth认证及授权流程OAuth认证和授权的过程如下： Client请求Resource Owner授权，请求一般包含：要访问的资源路径，操作类型，Client的身份等信息。 ResourceOwner批准授权，并将“授权证据”发送给Client。典型的做法是，AuthorizationServer 提供授权审批界面，让ResourceOwner显式批准。 Client使用上一步获得的Token，想AuthorizationServer申请令牌。 认证服务器对客户端进行认证后，确认无误后统一发放令牌。 Client携带“访问令牌”访问ResourceServer上的资源。在令牌的有效期内，Client可以多次携带令牌去访问资源。 ResourceServer验证令牌的有效性，比如是否伪造、是否越权、是否过期，通过验证后，才能提供服务。 OAuth 2.0&emsp;&emsp;OAuth 2.0定义了四种授权方式。 授权码模式（authorization code） 简化模式（implicit） 密码模式（resource owner password credentials） 客户端模式（client credentials） 授权码模式是功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与”服务提供商”的认证服务器进行互动。 流程图如下： 用户访问客户端，后者将前者导向认证服务器。 用户选择是否给予客户端授权。 假设用户给予授权，认证服务器将用户导向客户端事先指定的”重定向URI”（redirection URI），同时附上一个授权码。 客户端收到授权码，附上早先的”重定向URI”，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。 认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"OAuth","slug":"OAuth","permalink":"/tags/OAuth/"}]},{"title":"jdk编年史","date":"2017-08-04T11:57:58.000Z","path":"2017/08/04/jdk编年史/","text":"&emsp;&emsp;Java语言自JDK 1.0版本以来经历了许多次更新，也大量在基本的程序库中增加了类别和包。从J2SE 1.4开始，Java语言的变动受到Java Community Process（JCP）的约束，JCP使用Java规范请求来建议和定义对Java平台内容的新增和修改。 Java 8.0函数式接口Java 8 引入的一个核心概念是函数式接口（Functional Interfaces）。通过在接口里面添加一个抽象方法，这些方法可以直接从接口中运行。如果一个接口定义个唯一一个抽象方法，那么这个接口就成为函数式接口。同时，引入了一个新的注解：@FunctionalInterface。可以把他它放在一个接口前，表示这个接口是一个函数式接口。这个注解是非必须的，只要接口只包含一个方法的接口，虚拟机会自动判断，不过最好在接口上使用注解 @FunctionalInterface 进行声明。在接口中添加了 @FunctionalInterface 的接口，只允许有一个抽象方法，否则编译器也会报错。 java.lang.Runnable 就是一个函数式接口。 1234@FunctionalInterfacepublic interface Runnable &#123;public abstract void run();&#125; Lambda表达式函数式接口的重要属性是：我们能够使用 Lambda 实例化它们，Lambda 表达式让你能够将函数作为方法参数，或者将代码作为数据对待。Lambda 表达式的引入给开发者带来了不少优点：在 Java 8 之前，匿名内部类，监听器和事件处理器的使用都显得很冗长，代码可读性很差，Lambda 表达式的应用则使代码变得更加紧凑，可读性增强；Lambda 表达式使并行操作大集合变得很方便，可以充分发挥多核 CPU 的优势，更易于为多核处理器编写代码； Lambda 表达式由三个部分组成：第一部分为一个括号内用逗号分隔的形式参数，参数是函数式接口里面方法的参数；第二部分为一个箭头符号：-&gt;；第三部分为方法体，可以是表达式和代码块。语法如下： 方法体为表达式，该表达式的值作为返回值返回。 1(parameters) -&gt; expression 方法体为代码块，必须用 {} 来包裹起来，且需要一个 return 返回值，但若函数式接口里面方法返回值是 void，则无需返回值。 12(parameters) -&gt; &#123; statements; &#125;例如，下面是使用匿名内部类和 Lambda 表达式的代码比较。 Java 8 在 java.util.function 中增加了不少新的函数式通用接口。例如：Function&lt;T, R&gt;：将 T 作为输入，返回 R 作为输出，他还包含了和其他函数组合的默认方法。Predicate ：将 T 作为输入，返回一个布尔值作为输出，该接口包含多种默认方法来将 Predicate 组合成其他复杂的逻辑（与、或、非）。Consumer ：将 T 作为输入，不返回任何内容，表示在单个参数上的操作。 接口的增强Java 8 对接口做了进一步的增强。在接口中可以添加使用 default 关键字修饰的非抽象方法。还可以在接口中定义静态方法。如今，接口看上去与抽象类的功能越来越类似了。 默认方法 Java 8 还允许我们给接口添加一个非抽象的方法实现，只需要使用 default 关键字即可，这个特征又叫做扩展方法。在实现该接口时，该默认扩展方法在子类上可以直接使用，它的使用方式类似于抽象类中非抽象成员方法。但扩展方法不能够重载 Object 中的方法。例如：toString、equals、 hashCode 不能在接口中被重载。 例如，下面接口中定义了一个默认方法 count()，该方法可以在子类中直接使用。12345678910111213public interface DefaultFunInterface &#123;//定义默认方法 countdefault int count()&#123;return 1;&#125;&#125;public class SubDefaultFunClass implements DefaultFunInterface &#123;public static void main(String[] args)&#123;//实例化一个子类对象，改子类对象可以直接调用父接口中的默认方法 count SubDefaultFunClass sub = new SubDefaultFunClass();sub.count();&#125;&#125; 静态方法在接口中，还允许定义静态的方法。接口中的静态方法可以直接用接口来调用。例如，下面接口中定义了一个静态方法 find，该方法可以直接用 StaticFunInterface .find() 来调用。1234567891011public interface StaticFunInterface &#123;public static int find()&#123;return 1;&#125;&#125;public class TestStaticFun &#123;public static void main(String[] args)&#123;//接口中定义了静态方法 find 直接被调用StaticFunInterface.fine();&#125;&#125; 集合之流式操作Java 8 引入了流式操作（Stream），通过该操作可以实现对集合（Collection）的并行处理和函数式操作。根据操作返回的结果不同，流式操作分为中间操作和最终操作两种。最终操作返回一特定类型的结果，而中间操作返回流本身，这样就可以将多个操作依次串联起来。根据流的并发性，流又可以分为串行和并行两种。流式操作实现了集合的过滤、排序、映射等功能。 Stream 和 Collection 集合的区别：Collection 是一种静态的内存数据结构，而 Stream 是有关计算的。前者是主要面向内存，存储在内存中，后者主要是面向 CPU，通过 CPU 实现计算。 串行和并行的流 流有串行和并行两种，串行流上的操作是在一个线程中依次完成，而并行流则是在多个线程上同时执行。并行与串行的流可以相互切换：通过 stream.sequential() 返回串行的流，通过 stream.parallel() 返回并行的流。相比较串行的流，并行的流可以很大程度上提高程序的执行效率。 下面是分别用串行和并行的方式对集合进行排序。 串行排序：12345678910List&lt;String&gt; list = new ArrayList&lt;String&gt;();for(int i=0;i&lt;1000000;i++)&#123;double d = Math.random()*1000;list.add(d+\"\");&#125;long start = System.nanoTime();//获取系统开始排序的时间点int count= (int) ((Stream) list.stream().sequential()).sorted().count();long end = System.nanoTime();//获取系统结束排序的时间点long ms = TimeUnit.NANOSECONDS.toMillis(end-start);//得到串行排序所用的时间System.out.println(ms+”ms”); 并行排序：12345678910List&lt;String&gt; list = new ArrayList&lt;String&gt;();for(int i=0;i&lt;1000000;i++)&#123;double d = Math.random()*1000;list.add(d+\"\");&#125;long start = System.nanoTime();//获取系统开始排序的时间点int count = (int)((Stream) list.stream().parallel()).sorted().count();long end = System.nanoTime();//获取系统结束排序的时间点long ms = TimeUnit.NANOSECONDS.toMillis(end-start);//得到并行排序所用的时间System.out.println(ms+”ms”); 中间操作 该操作会保持 stream 处于中间状态，允许做进一步的操作。它返回的还是的 Stream，允许更多的链式操作。常见的中间操作有：filter()：对元素进行过滤；sorted()：对元素排序；map()：元素的映射；distinct()：去除重复元素；subStream()：获取子 Stream 等。 例如，下面是对一个字符串集合进行过滤，返回以“s”开头的字符串集合，并将该集合依次打印出来：123list.stream().filter((s) -&gt; s.startsWith(\"s\")).forEach(System.out::println); 注解的更新对于注解，Java 8 主要有两点改进：类型注解和重复注解。Java 8 的类型注解扩展了注解使用的范围。在该版本之前，注解只能是在声明的地方使用。现在几乎可以为任何东西添加注解：局部变量、类与接口，就连方法的异常也能添加注解。新增的两个注释的程序元素类型 ElementType.TYPE_USE 和 ElementType.TYPE_PARAMETER 用来描述注解的新场合。ElementType.TYPE_PARAMETER 表示该注解能写在类型变量的声明语句中。而 ElementType.TYPE_USE 表示该注解能写在使用类型的任何语句中（例如声明语句、泛型和强制转换语句中的类型）。 在编译的时候被排查出来。Java 8 本身虽然没有自带类型检测的框架，但可以通过使用 Checker Framework 这样的第三方工具，自动检查和确认软件的缺陷，提高生产效率。 例如，下面的代码可以通过编译，但是运行时会报 NullPointerException 的异常。 123456public class TestAnno &#123;public static void main(String[] args) &#123;Object obj = null;obj.toString();&#125;&#125; 为了能在编译期间就自动检查出这类异常，可以通过类型注解结合 Checker Framework 提前排查出来：1234567import org.checkerframework.checker.nullness.qual.NonNull;public class TestAnno &#123;public static void main(String[] args) &#123;@NonNull Object obj = null;obj.toString();&#125;&#125; 编译时自动检测结果如下：1234567C:\\workspace\\TestJava8\\src\\TestAnno.java:4: Warning: (assignment.type.incompatible) $$ 2 $$ null $$ @UnknownInitialization @NonNull Object $$ ( 152, 156 ) $$ incompatible types in assignment.@NonNull Object obj = null; ^ found : null required: @UnknownInitialization @NonNull Object 重复注解 另外，在该版本之前使用注解的一个限制是相同的注解在同一位置只能声明一次，不能声明多次。Java 8 引入了重复注解机制，这样相同的注解可以在同一地方声明多次。重复注解机制本身必须用 @Repeatable 注解。 1234567891011121314151617181920@Retention(RetentionPolicy.RUNTIME) \\\\该注解存在于类文件中并在运行时可以通过反射获取@interface Annots &#123;Annot[] value();&#125; @Retention(RetentionPolicy.RUNTIME) \\\\该注解存在于类文件中并在运行时可以通过反射获取@Repeatable(Annots.class)@interface Annot &#123;String value();&#125;@Annot(\"a1\")@Annot(\"a2\")public class Test &#123;public static void main(String[] args) &#123;Annots annots1 = Test.class.getAnnotation(Annots.class);System.out.println(annots1.value()[0]+\",\"+annots1.value()[1]); // 输出: @Annot(value=a1),@Annot(value=a2)Annot[] annots2 = Test.class.getAnnotationsByType(Annot.class);System.out.println(annots2[0]+\",\"+annots2[1]); // 输出: @Annot(value=a1),@Annot(value=a2)&#125;&#125; 注释 Annot 被 @Repeatable( Annots.class ) 注解。Annots 只是一个容器，它包含 Annot 数组, 编译器尽力向程序员隐藏它的存在。通过这样的方式，Test 类可以被 Annot 注解两次。重复注释的类型可以通过 getAnnotationsByType() 方法来返回。 安全性Java 8 在安全性上对许多方面进行了增强，也为此推迟了它的发布日期。下面例举其中几个关于安全性的更新： 支持更强的基于密码的加密算法。基于 AES 的加密算法，例如 PBEWithSHA256AndAES_128 和 PBEWithSHA512AndAES_256，已经被加入进来。 在客户端，TLS1.1 和 TLS1.2 被设为默认启动。并且可以通过新的系统属性包 jdk.tls.client.protocols 来对它进行配置。 Keystore 的增强，包含新的 Keystore 类型 java.security.DomainLoadStoreParameter 和为 Keytool 这个安全钥匙和证书的管理工具添加新的命令行选项-importpassword。同时，添加和更新了一些关于安全性的 API 来支持 KeyStore 的更新。 支持安全的随机数发生器。如果随机数来源于随机性不高的种子，那么那些用随机数来产生密钥或者散列敏感信息的系统就更易受攻击。SecureRandom 这个类的 getInstanceStrong 方法如今可以获取各个平台最强的随机数对象实例，通过这个实例生成像 RSA 私钥和公钥这样具有较高熵的随机数。 安全性比较差的加密方法被默认禁用。默认不支持 DES 相关的 Kerberos 5 加密方法。如果一定要使用这类弱加密方法需要在 krb5.conf 文件中添加 allow_weak_crypto=true。考虑到这类加密方法安全性极差，开发者应该尽量避免使用它。 IO/NIO的改进Java 8 对 IO/NIO 也做了一些改进。主要包括：改进了 java.nio.charset.Charset 的实现，使编码和解码的效率得以提升，也精简了 jre/lib/charsets.jar 包；优化了 String(byte[],*) 构造方法和 String.getBytes() 方法的性能；还增加了一些新的 IO/NIO 方法，使用这些方法可以从文件或者输入流中获取流（java.util.stream.Stream），通过对流的操作，可以简化文本行处理、目录遍历和文件查找。 新增的 API 如下：BufferedReader.line(): 返回文本行的流 StreamFile.lines(Path, Charset):返回文本行的流 StreamFile.list(Path): 遍历当前目录下的文件和目录File.walk(Path, int, FileVisitOption): 遍历某一个目录下的所有文件和指定深度的子目录File.find(Path, int, BiPredicate, FileVisitOption… ): 查找相应的文件 下面就是用流式操作列出当前目录下的所有文件和目录：12Files.list(new File(\".\").toPath()) .forEach(System.out::println); 全球化功能Java 8 吸收了 Joda-Time 的精华，以一个新的开始为 Java 创建优秀的 API。新的 java.time 中包含了所有关于时钟（Clock），本地日期（LocalDate）、本地时间（LocalTime）、本地日期时间（LocalDateTime）、时区（ZonedDateTime）和持续时间（Duration）的类。历史悠久的 Date 类新增了 toInstant() 方法，用于把 Date 转换成新的表示形式。这些新增的本地化时间日期 API 大大简化了了日期时间和本地化的管理。 12345678910111213LocalDate localDate = LocalDate.now(); //获取本地日期localDate = LocalDate.ofYearDay(2014, 200); // 获得 2014 年的第 200 天 System.out.println(localDate.toString());//输出：2014-07-19localDate = LocalDate.of(2014, Month.SEPTEMBER, 10); //2014 年 9 月 10 日 System.out.println(localDate.toString());//输出：2014-09-10//LocalTimeLocalTime localTime = LocalTime.now(); //获取当前时间System.out.println(localTime.toString());//输出当前时间localTime = LocalTime.of(10, 20, 50);//获得 10:20:50 的时间点System.out.println(localTime.toString());//输出: 10:20:50//Clock 时钟Clock clock = Clock.systemDefaultZone();//获取系统默认时区 (当前瞬时时间 )long millis = clock.millis();// 并发在新增Stream机制与lambda的基础之上，在java.util.concurrent.ConcurrentHashMap中加入了一些新方法来支持聚集操作。同时也在java.util.concurrent.ForkJoinPool类中加入了一些新方法来支持共有资源池（common pool） 新增的java.util.concurrent.locks.StampedLock类提供一直基于容量的锁，这种锁有三个模型来控制读写操作（它被认为是不太有名的java.util.concurrent.locks.ReadWriteLock类的替代者）。 在java.util.concurrent.atomic包中还增加了下面这些类 DoubleAccumulator DoubleAdder LongAccumulator LongAdder 使用了java.util.concurrent.atomic则这些操作都是具有原子性的。【注意】对于32位操作系统来说，单次次操作能处理的最长长度为32bit，而long类型8字节64bit，所以对long的读写都要两条指令才能完成（即每次读写64bit中的32bit）。如果JVM要保证long和double读写的原子性，势必要做额外的处理。 那么，JVM有对这一情况进行额外处理吗？针对这一问题可以参考Java语言规范文档：jls-17 Non-Atomic Treatment of double and long 从规定中我们可以知道: 对于64位的long和double，如果没有被volatile修饰，那么对其操作可以不是原子的。在操作的时候，可以分成两步，每次对32位操作。 如果使用volatile修饰long和double，那么其读写都是原子操作 对于64位的引用地址的读写，都是原子操作 在实现JVM时，可以自由选择是否把读写long和double作为原子操作 推荐JVM实现为原子操作 对于64bit的环境来说，单次操作可以操作64bit的数据，即可以以一次性读写long或double的整个64bit。因此在64位的环境下，long和double的读写是原子操作。 JVM的新特性JVM内存永久区已经被metaspace替换（JEP 122）。JVM参数 -XX:PermSize 和 –XX:MaxPermSize被XX:MetaSpaceSize 和 -XX:MaxMetaspaceSize代替。 Java 7.0switch中可以使用字串1234567891011121314151617181920212223Java代码： String s = \"test\"; switch (s) &#123; case \"test\" : System.out.println(\"test\"); case \"test1\" : System.out.println(\"test1\"); break ; default : System.out.println(\"break\"); break ; &#125; 对集合类的语言支持；Java将包含对创建集合类的第一类语言支持。这意味着集合类的创建可以像Ruby和Perl那样了。创建List / Set / Map 时写法更简单了。 12345678910111213141516//Java 1.7以前List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(\"item\"); String item = list.get(0); Set&lt;String&gt; set = new HashSet&lt;String&gt;(); set.add(\"item\"); Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;(); map.put(\"key\", 1); int value = map.get(\"key\"); 12345678910//Java 1.7支持List&lt; String&gt; list = [\"item\"]; String item = list[0]; Set&lt; String &gt; set = &#123;\"item\"&#125;; Map&lt; String,Integer &gt; map = &#123;\"key\" : 1&#125;; int value = map[\"key\"]; 自动资源管理；Java中某些资源是需要手动关闭的，如InputStream，Writes，Sockets，Sql classes等。这个新的语言特性允许try语句本身申请更多的资源， 这些资源作用于try代码块，并自动关闭。123456789101112//Java 1.7以前BufferedReader br = new BufferedReader(new FileReader(path)); try &#123; return br.readLine(); &#125; finally &#123; br.close(); &#125; 123456//Java 1.7支持 try (BufferedReader br = new BufferedReader(new FileReader(path)) &#123; return br.readLine(); &#125; 改进的通用实例创建类型推断；Java 1.7增强的对通用实例创建（diamond）的类型推断 类型推断是一个特殊的烦恼，下面的代码：1Map&lt;String, List&lt;String&gt;&gt; anagrams = new HashMap&lt;String, List&lt;String&gt;&gt;(); 通过类型推断后变成：1Map&lt;String, List&lt;String&gt;&gt; anagrams = new HashMap&lt;&gt;(); 这个&lt;&gt;被叫做diamond（钻石）运算符，这个运算符从引用的声明中推断类型。 数字字面量下划线支持；很长的数字可读性不好，在Java 7中可以使用下划线分隔长int以及long了1int one_million = 1_000_000; 运算时先去除下划线，如：1_1 * 10 = 110，120 – 1_0 = 110 二进制字面量；由于继承C语言，Java代码在传统上迫使程序员只能使用十进制，八进制或十六进制来表示数(numbers)。 由于很少的域是以bit导向的，这种限制可能导致错误。你现在可以使用0b前缀创建二进制字面量：1int binary = 0b1001_1001; 简化可变参数方法调用；程序员试图使用一个不可具体化的可变参数并调用一个varargs （可变）方法时，编辑器会生成一个“非安全操作”的警告。 JDK 7将警告从call转移到了方法声明(methord declaration)的过程中。这样API设计者就可以使用vararg，因为警告的数量大大减少了。 新增一些取环境信息的工具方法；1234567File System.getJavaIoTempDir() // IO临时文件夹 File System.getJavaHomeDir() // JRE的安装目录 File System.getUserHomeDir() // 当前用户目录 File System.getUserDir() // 启动java进程时所在的目录 Boolean类型反转，空指针安全,参与位运算；123456789101112131415Boolean Booleans.negate(Boolean booleanObj) True =&gt; False , False =&gt; True, Null =&gt; Null boolean Booleans.and( boolean [] array) boolean Booleans.or( boolean [] array) boolean Booleans.xor( boolean [] array) boolean Booleans.and(Boolean[] array) boolean Booleans.or(Boolean[] array) boolean Booleans.xor(Boolean[] array) 两个char间的equals；1boolean Character.equalsIgnoreCase( char ch1, char ch2) 安全的加减乘除；1234567891011121314151617181920212223int Math.safeToInt( long value) int Math.safeNegate( int value) long Math.safeSubtract( long value1, int value2) long Math.safeSubtract( long value1, long value2) int Math.safeMultiply( int value1, int value2) long Math.safeMultiply( long value1, int value2) long Math.safeMultiply( long value1, long value2) long Math.safeNegate( long value) int Math.safeAdd( int value1, int value2) long Math.safeAdd( long value1, int value2) long Math.safeAdd( long value1, long value2) int Math.safeSubtract( int value1, int value2) G1垃圾回收器平时工作中大多数系统都使用CMS、即使静默升级到JDK7默认仍然采用CMS、那么G1相对于CMS的区别在： G1在压缩空间方面有优势 G1通过将内存空间分成区域（Region）的方式避免内存碎片问题 Eden, Survivor, Old区不再固定、在内存使用效率上来说更灵活 G1可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间避免应用雪崩现象 G1在回收内存后会马上同时做合并空闲内存的工作、而CMS默认是在STW（stop the world）的时候做 G1会在Young GC中使用、而CMS只能在O区使用 JAVA 6.0Instrumentation 新功能Java SE 6 在 Instrumentation 方面的新特性。在 Java SE 6 里面，instrumentation 包被赋予了更强大的功能：启动后的instrument、本地代码 instrument，以及动态改变 classpath 等等。 HTTP 增强在 Java SE 6 之前， Java 一直都没有提供 Cookie 管理的功能。在 Java SE 5 里面， java.net 包里面有一个 CookieHandler 抽象类，不过并没有提供其他具体的实现。到了 Java SE 6， Cookie 相关的管理类在 Java 类库里面才得到了实现。有了这些 Cookie 相关支持的类，Java 开发者可以在服务器端编程中很好的操作 Cookie， 更好的支持 HTTP 相关应用，创建有状态的 HTTP 会话。 用 HttpCookie 代表 Cookiejava.net.HttpCookie 类是 Java SE 6 新增的一个表示 HTTP Cookie 的新类， 其对象可以表示 Cookie 的内容， 可以支持所有三种 Cookie 规范：Netscape 草案RFC 2109 - http://www.ietf.org/rfc/rfc2109.txtRFC 2965 - http://www.ietf.org/rfc/rfc2965.txt这个类储存了 Cookie 的名称，路径，值，协议版本号，是否过期，网络域，最大生命期等等信息。 用 CookiePolicy 规定 Cookie 接受策略java.net.CookiePolicy 接口可以规定 Cookie 的接受策略。 其中唯一的方法用来判断某一特定的 Cookie 是否能被某一特定的地址所接受。 这个类内置了 3 个实现的子类。一个类接受所有的 Cookie，另一个则拒绝所有，还有一个类则接受所有来自原地址的 Cookie。 用 CookieStore 储存 Cookiejava.net.CookieStore 接口负责储存和取出 Cookie。 当有 HTTP 请求的时候，它便储存那些被接受的 Cookie； 当有 HTTP 回应的时候，它便取出相应的 Cookie。 另外，当一个 Cookie 过期的时候，它还负责自动删去这个 Cookie。 用 CookieManger/CookieHandler 管理 Cookiejava.net.CookieManager 是整个 Cookie 管理机制的核心，它是 CookieHandler 的默认实现子类。下图显示了整个 HTTP Cookie 管理机制的结构： 一个 CookieManager 里面有一个 CookieStore 和一个 CookiePolicy，分别负责储存 Cookie 和规定策略。用户可以指定两者，也可以使用系统默认的 CookieManger。 12345678910111213141516171819202122232425262728293031323334// 创建一个默认的 CookieManager CookieManager manager = new CookieManager(); // 将规则改掉，接受所有的 Cookie manager.setCookiePolicy(CookiePolicy.ACCEPT_ALL); // 保存这个定制的 CookieManager CookieHandler.setDefault(manager); // 接受 HTTP 请求的时候，得到和保存新的 Cookie HttpCookie cookie = new HttpCookie(\"...(name)...\",\"...(value)...\"); manager.getCookieStore().add(uri, cookie); // 使用 Cookie 的时候：// 取出 CookieStore CookieStore store = manager.getCookieStore(); // 得到所有的 URI List&lt;URI&gt; uris = store.getURIs(); for (URI uri : uris) &#123; // 筛选需要的 URI // 得到属于这个 URI 的所有 Cookie List&lt;HttpCookie&gt; cookies = store.get(uri); for (HttpCookie cookie : cookies) &#123; // 取出了 Cookie &#125; &#125; // 或者，取出这个 CookieStore 里面的全部 Cookie // 过期的 Cookie 将会被自动删除List&lt;HttpCookie&gt; cookies = store.getCookies(); for (HttpCookie cookie : cookies) &#123; // 取出了 Cookie &#125; JDK1.6 提供了一个简单的Http Server API，据此我们可以构建自己的嵌入式Http Server，它支持Http和Https协议，提供了HTTP1.1的部分实现，没有被实现的那部分可以通过扩展已有的Http Server API来实现，程序员必须自己实现HttpHandler接口，HttpServer会调用HttpHandler实现类的回调方法来处理客户端请求，在这里，我们把一个Http请求和它的响应称为一个交换，包装成HttpExchange类，HttpServer负责将HttpExchange传给HttpHandler实现类的回调方法。 使用JAXB2来实现对象与XML之间的映射JAXB是Java Architecture for XML Binding的缩写，可以将一个Java对象转变成为XML格式，反之亦然。我们把对象与关系数据库之间的映射称为ORM，其实也可以把对象与XML之间的映射称为OXM(Object XML Mapping)。原来JAXB是Java EE的一部分，在JDK1.6中，SUN将其放到了Java SE中，这也是SUN的一贯做法。JDK1.6中自带的这个JAXB版本是2.0，比起1.0(JSR 31)来，JAXB2(JSR 222)用JDK5的新特性Annotation来标识要作绑定的类和属性等，这就极大简化了开发的工作量。实际上，在Java EE 5.0中，EJB和Web Services也通过Annotation来简化开发工作。另外，JAXB2在底层是用StAX(JSR 173)来处理XML文档。 除了JAXB之外，我们还可以通过XMLBeans和Castor等来实现同样的功能。 脚本语言支持支持ruby，groovy，javascript。 Java SE 6 还为运行脚本添加了一个专门的工具 —— jrunscript。jrunscript 支持两种运行方式：一种是交互式，即边读取边解析运行，这种方式使得用户可以方便调试脚本程序，马上获取预期结果；还有一种就是批处理式，即读取并运行整个脚本文件。用户可以把它想象成一个万能脚本解释器，即它可以运行任意脚本程序，而且它还是跨平台的，当然所有这一切都有一个前提，那就是必须告诉它相应的脚本引擎的位置。默认即支持的脚本是 JavaScript，这意味着用户可以无需任何设置，通过 jrunscript 在任何支持 Java 的平台上运行任何 JavaScript 脚本；如果想运行其他脚本，可以通过 -l 指定以何种脚本引擎运行脚本。不过这个工具仍是实验性质的，不一定会包含在 Java 的后续版本中，无论如何，它仍是一个非常有用的工具。 Java DB 和 JDBC 4.0新安装了 JDK 6 的程序员们也许会发现，除了传统的 bin、jre 等目录，JDK 6 新增了一个名为 db 的目录。这便是 Java 6 的新成员：Java DB。这是一个纯 Java 实现、开源的数据库管理系统（DBMS），源于 Apache 软件基金会（ASF）名下的项目 Derby。它只有 2MB 大小，对比动辄上 G 的数据库来说可谓袖珍。但这并不妨碍 Derby 功能齐备，支持几乎大部分的数据库应用所需要的特性。更难能可贵的是，依托于 ASF 强大的社区力量，Derby 得到了包括 IBM 和 Sun 等大公司以及全世界优秀程序员们的支持。这也难怪 Sun 公司会选择其 10.2.2 版本纳入到 JDK 6 中，作为内嵌的数据库。 编译器APIJDK 6 提供了在运行时调用编译器的 API，后面我们将假设把此 API 应用在 JSP 技术中。在传统的 JSP 技术中，服务器处理 JSP 通常需要进行下面 6 个步骤： 分析 JSP 代码； 生成 Java 代码； 将 Java 代码写入存储器； 启动另外一个进程并运行编译器编译 Java 代码； 将类文件写入存储器； 服务器读入类文件并运行；但如果采用运行时编译，可以同时简化步骤 4 和 5，节约新进程的开销和写入存储器的输出开销，提高系统效率。实际上，在 JDK 5 中，Sun 也提供了调用编译器的编程接口。然而不同的是，老版本的编程接口并不是标准 API 的一部分，而是作为 Sun 的专有实现提供的，而新版则带来了标准化的优点。新 API 的第二个新特性是可以编译抽象文件，理论上是任何形式的对象 —— 只要该对象实现了特定的接口。有了这个特性，上述例子中的步骤 3 也可以省略。整个 JSP 的编译运行在一个进程中完成，同时消除额外的输入输出操作。第三个新特性是可以收集编译时的诊断信息。作为对前两个新特性的补充，它可以使开发人员轻松的输出必要的编译错误或者是警告信息，从而省去了很多重定向的麻烦。 JAVA 5.0自动装箱/拆箱(Auto-Boxing/Unboxing)没有自动装箱/拆箱：123int int1 = 1;Integer integer2 = new Integer(int1);int int3 = integer2.intValue(); 有自动装箱/拆箱：123int int1 = 1;Integer integer2 = int1; // 自動裝箱int int3 = integer2; // 自動拆箱 泛型(Generic Types)泛型就像是C++的模板。原有的Collection API加上泛型支持后，增加对类型的检查，减少程序错误的机会。 注释(Annotation)Java的注释是一种接口 (interface)，继承自java.lang.annotation.Annotation。Class File则粘贴ACC_ANNOTATION标签。从5.0开始，javadoc的@deprecated(代表不建议使用的方法或类别)也被Annotation中的@Deprecated取代；另外，使用Java 实现SOP的AspectJ与Spring也使用了大量的Annotation。1234567// JDK 1.4/*** @todo to be implemented**/void gimmeSomeLoving() &#123; throw new Exception(\"not implemented\");&#125; 1234// JDK 1.5@todo void gimmeSomeLoving() &#123; throw new Exception(\"not implemented\");&#125; 枚举类型(enum)枚举类型也是J2SE 5.0的新功能。过去Java认为enum的关键字是不必要的功能，因为用public static int field就可以取代enum，因此过去一直不用。J2SE 5.0中的class如果是enum，在class file中会被粘贴一个ACC_ENUM标签。 123456// JDK 1.4 class JavaTech &#123; public static final int J2ME = 1; public static final int J2SE = 2; public static final int J2EE = 3; &#125; 1234// JDK 1.5 public enum NewJavaTech &#123; J2ME, J2SE, J2EE &#125; 字符国际化Java语言严格区分字节和字符。字符的存储格式为UCS-2，也就是只能使用位于基本多文种平面的字符，从Java 5开始支持UTF-16字符。另外，从5.0开始Java的程序也开始可以使用Unicode字符进行命名。 123public class HelloWorld &#123; private String文本 = \"HelloWorld\";&#125; 输入输出在jdk1.5及其以后版本中，java.util.Scanner和java.util.Formatter类别被应用到输入输出中。另外，也出现了类似C语言的printf()函数。 foreach 循环foreach循环，有时又称forin循环，在许多编程语言（包括C#、Ruby、JavaScript）中都有出现，可以直接将一个Array或Map展开，而不必程序员自行检查边界，可以有效减少错误的机会。 12345int[] array1 = &#123;1, 3, 5&#125;;for(int i : array1)&#123; // foreach迴圈 System.out.println(\"Number: \"+i);&#125; 可变长度引数长久以来一直有用户要求加入printf()函数，受限于Java函数必须要有固定引数的限制，始终无法实现，在加入这个功能之后，连带printf()也变为可能。 static引入这个特性允许程序员将一个类别中的静态内容引入到程序中。1234567static import java.lang.System.*;public class HelloWorld &#123; public static void main(String args[])&#123; out.println(\"Hello World.\"); &#125;&#125; 线程并发库线程并发库是Java1.5提出的关于多线程处理的高级功能，所在包：java.util.concurrent包括 线程互斥 工具类描述：Lock，ReadWriteLock 线程通信 描述：Condition 线程池 ExecutorService 同步队列 ArrayBlockingQueue 同步集合 ConcurrentHashMap，CopyOnWriteArrayList 线程同步工具 Semaphore","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"record","slug":"record","permalink":"/tags/record/"}]},{"title":"java高并发","date":"2017-08-02T12:32:11.000Z","path":"2017/08/02/java高并发/","text":"","categories":[],"tags":[]},{"title":"数据库的整理笔记","date":"2017-08-01T07:50:09.000Z","path":"2017/08/01/数据库的整理笔记/","text":"索引 聚集索引：索引键值的逻辑顺序与索引所服务的表中相应行的物理顺序相同的索引。 非聚集索引：索引键值的逻辑顺序与索引所服务的表中相应行的物理顺序不相同的索引。 唯一索引：唯一索引是不允许其中任何两行具有相同索引值的索引。 主键索引：主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问。 &emsp;&emsp;聚集索引的索引值是直接指向数据表对应元组的，而非聚集索引的索引值仍会指向下一个索引数据块，不直接指向元组，因为还有一层索引进行重定向，所以非聚集索引可以拥有不同的键值排序而拥有多个不同的索引。而聚集索引因为与表的元组物理顺序一一对应，所以只有一种排序，即一个数据表只有一个聚集索引。 建索引的几大原则 最左端前缀匹配原则：mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)。 “=”和“in”可以乱序，比如a = 1 and b = 2 and c = 3建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。 尽量选择区分度高的列作为索引，区分度=count(distinct col)/count(*)，表示字段不重复的比例，比例越大，扫描的记录数越少，唯一键的区分度为1。一般需要join的字段的要求是区分度在0.1以上，即平均1条扫描10条记录。 索引列不能参与计算，需要保持列“干净”。例如from_unixtime(create_time) = ‘2017-08-04’需要改写为create_time = unix_timestamp(‘2017-08-04’)。 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。 应该创建索引的列 在经常需要搜索的列上，可以加快搜索的速度； 在经常需要排列的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间； 在经常使用在WHERE子句的列上面创建索引，加快条件的判断速度； 在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构； 在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度； 在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的； 不应该创建索引的列第一，对于那些在查询中使用很少或者作为参考的列不应该创建索引。第二，对于那些只有很少数据值的列不应该增加索引。第三，对于那些定义为text,image和bit数据类型的列不应该增加索引。因为这些列的数据量要么很大，要么很少。第四，当修改性能远远大于检索性能时，不应该创建索引。 聚集索引定义：在聚集索引中，叶节点即数据节点，所有数据航的存储顺序与索引的存储顺序一致。 当需要在根据此字段查找特定的记录时，数据库系统会根据特定的系统表查找的此索引的根，然后根据指针查找下一个，直到找到。例如我们要查询“Green”，由于它介于[Bennet,Karsen]，据此我们找到了索引页1007，在该页中“Green”介于[Greane, Hunter]间，据此我们找到叶结点1133（也即数据结点），并最终在此页中找以了目标数据行。 非聚集索引聚集索引是一种稀疏索引，数据页上一级的索引页存储的是页指针，而不是行指针。而对于非聚集索引，则是密集索引，在数据页的上一级索引页它为每一个数据行存储一条索引记录。 非聚集索引与聚集索引对比A）叶子结点并非数据结点B）叶子结点为每一真正的数据行存储一个“键-指针”对C）叶子结点中还存储了一个指针偏移量，根据页指针及指针偏移量可以定位到具体的数据行。D）类似的，在除叶结点外的其它索引结点，存储的也是类似的内容，只不过它是指向下一级的索引页的。 索引的实现原理&emsp;&emsp;索引一般采用B树/B+树来实现，当然也有例外，Memory引擎显示支持哈希索引，我们接下来分别进行讨论。 B-Tree索引&emsp;&emsp;B-Tree是MyISAM和InnoDB引擎默认索引类型,也可以在创建索引时通过USING BTREE来显示指定。B-Tree是一种多叉平衡树,B-Tree 结构可以显著减少定位记录时所经历的中间过程,从而加快存取速度。一般用于数据库的索引,综合效率较高。 B-Tree索引的应用场景- 等值匹配 可用于= != &lt;&gt; IN NOT IN &lt;=&gt;查询语句的优化 - 范围匹配 可用于 &gt; &gt;= &lt; &lt;= BTEWEEN AND等范围查询语句的优化 - 匹配最左前缀 对于 name like bai% 这种后模糊匹配的查询,是可以利用name字段上建立的索引来优化查询的,但是对于name like %bai这种前模糊匹配的查询则没有办法使用索引了 - 覆盖索引 B-Tree索引的key存放的是字段的值,如果key中包含所有需要查询字段的值,我们就称之为覆盖索引,覆盖索引能够极大的提高性能。 - 排序 B-Tree索引是排好序的,所以MySQL可以用来优化ORDER BY 和 GROUP BY等操作。 哈希索引(HASH)&emsp;&emsp;哈希索引基于哈希表实现,只有Memory引擎显示支持哈希索引,使用哈希索引可以一次定位,所以 Hash 索引的查询效率要远高于 B-Tree 索引。但是哈希索引是有很多限制的: - 只有精确匹配索引所有列的查询才有效,因为哈希索引是利用索引的所有列的字段值来计算哈希值的。 - 只支持等值比较查询,不能用于范围查询。 - 哈希索引的只包含索引字段的哈希值和指向数据的指针,所以不能使用索引中的值来避免读取行。 - 哈希索引的数据并不是顺序存储的,无法用于排序。 全文索引(FULLTEXT)全文索引,是一种通过建立倒排索引,快速匹配文档的方式。 空间索引(SPATIAL)MyISAM支持空间索引,可以用作地理数据的存储。 InnoDB与MyISAM的区别 InnoDB支持事务，MyISAM不支持，这一点是非常之重要。事务是一种高级的处理方式，如在一些列增删改中只要哪个出错还可以回滚还原，而MyISAM就不可以了。 MyISAM适合查询以及插入为主的应用，InnoDB适合频繁修改以及涉及到安全性较高的应用 InnoDB支持外键，MyISAM不支持 MyISAM是默认引擎，InnoDB需要指定 InnoDB不支持FULLTEXT类型的索引 InnoDB中不保存表的行数，如select count(*) from table时，InnoDB需要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count(*)语句包含where条件时MyISAM也需要扫描整个表 对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引 清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表 InnoDB支持行锁（某些情况下还是锁整表，如 update table set a=1 where user like &#39;%lee%&#39;） 参考文献 维基百科：索引 MySQL索引原理及慢查询优化 数据库进阶系列之一：漫谈数据库索引 MySQL索引详解","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"record","slug":"record","permalink":"/tags/record/"},{"name":"MySQL","slug":"MySQL","permalink":"/tags/MySQL/"}]},{"title":"JIT--即时编译","date":"2017-07-31T08:51:54.000Z","path":"2017/07/31/JIT/","text":"JIT（Just-In-Time, 即时编译器）通常，程序有两种运行方式：静态编译与动态编译。静态编译的程序在执行前全部被翻译为机器码，而解释执行的则是一句一句边运行边翻译的。 Java字节码是解释执行的，但是没有直接在JVM宿主执行原生代码块。为了提高性能，Oracle Hotspot虚拟机会找到执行最频繁的字节码片段并把他们编译成原生机器码。编译出的原生机器码被存储在非堆内存的代码缓存中。在运行时JIT会把翻译过的机器码保存起来，以备下次使用。 JIT的工作原理图当JIT编译启用时（默认是启用的），JVM读入.class文件解释后，将其发给JIT编译器。JIT编译器将字节码编译成本机机器代码，它的工作原理图如下。 Hot Spot编译当JVM执行代码时，它并不立即开始编译代码，这主要有两个原因：首先，如果这段代码本身在将来只会执行一次，那么从本质上看，编译就是在浪费精力。因为将代码翻译成java字节码相对于编译这段代码并执行来说，要快的多。 当然，如果一段代码频繁的被调用，或是在一个循环中，那么编译就很有必要。隐藏，编译器具有的这种权衡能力会首先执行解释后的代码，然后再去分辨哪些方法会被频繁调用来保证其本身的编译。这就是JIT在起作用，对于Java代码，刚开始都是被编译器编译成字节码文件，然后字节码文件会被交由JVM解释执行，所以可以说Java本身死一种半编译半解释执行的语言。Hot Spot VM 采用了JIT compile技术，将运行频率很高的字节码直接编译为机器指令执行，以提高性能，所以当字节码被JIT编译为机器码的时候，要说它编译执行的也可以。也就是在运行时，部分代码可能由JIT翻译为目标机器指令直接执行（以method为翻译单位，同时会保存起来，当第二次执行时就不必翻译了）。 第二个原因是最优化。当JVM执行某一方法或遍历循环的次数越多，就会更加了解代码结构，那么JVM在编译代码的时候就做出相应的优化。 参考资料： JVM内幕：Java虚拟机详解 深入浅出JIT编译器","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"record","slug":"record","permalink":"/tags/record/"}]},{"title":"数据链路层的要点","date":"2017-07-29T07:16:54.000Z","path":"2017/07/29/Computer Network/","text":"主要解决三个基本问题 封装成帧 封装成帧通过SOH、EOT帧界定符来进行确认帧的边界，将物理层的二进制数据流封装成帧。 透明传输 透明传输是通过转义字符来解决的，通过转义字符解决数据内容中存在帧界定符时的特殊情况。 差错检测 差错检测是近似地认为凡是接收端数据链路层接受的帧均无差错。差错检测分为了无比特差错和无传输差错。 无比特差错：CRC（Cyclic Redundancy Check，循环冗余校验） 无传输差错：帧编号，帧确认和帧重传机制来实现 MTUMTU（Maximum Transmission Unit，最大传输单元）：数据链路层数据部分的长度，其默认值是1500字节。MTU不是越大越好，MTU越大意味着传送一个数据包的延迟也越大，bit位发生错误的概率就越大。 ARP是地址解析协议的工作原理。1：首先，每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系。 2：当源主机要发送数据时，首先检查ARP列表中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据，如果没有，就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机 IP地址，源主机MAC地址，目的主机的IP 地址。 3：当本网络的所有主机收到该ARP数据包时，首先检查数据包中的IP地址是否是自己的IP地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中，如果已经存在，则覆盖，然后将自己的MAC地址写入ARP响应包中，告诉源主机自己是它想要找的MAC地址。 4：源主机收到ARP响应包后。将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。 广播发送ARP请求，单播发送ARP响应。 RARP的工作原理RARP是逆地址解析协议，作用是完成硬件地址到IP地址的映射，主要用于无盘工作站，因为给无盘工作站配置的IP地址不能保存。工作流程：在网络中配置一台RARP服务器，里面保存着IP地址和MAC地址的映射关系，当无盘工作站启动后，就封装一个RARP数据包，里面有其MAC地址，然后广播到网络上去，当服务器收到请求包后，就查找对应的MAC地址的IP地址装入响应报文中发回给请求者。因为需要广播请求报文，因此RARP只能用于具有广播能力的网络。","categories":[{"name":"聚沙成塔","slug":"record","permalink":"/categories/record/"}],"tags":[{"name":"record","slug":"record","permalink":"/tags/record/"},{"name":"network","slug":"network","permalink":"/tags/network/"}]}]